{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86880d06",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Filter Method Training â€” Algorithm Families Overview\n",
    "\n",
    "#### ðŸ“Œ Ushbu bosqichda **filter-based feature selection** qo'llanilib, **FS - Filter Method** asosida **classification** uchun **jami 25 ta algoritm** turli model oilalaridan foydalanilgan.\n",
    "\n",
    "\n",
    "Quyida loyihada qoâ€˜llanilgan **asosiy algoritm oilalari** keltirilgan:\n",
    "\n",
    "- ðŸ“ **Linear Models**\n",
    "- ðŸŒ³ **Tree-Based Models**\n",
    "- ðŸ§  **Ensemble Models**\n",
    "- ðŸ‘¥ **Neighbors-Based Models**\n",
    "- ðŸ“ **Support Vector Machine (SVM) Models**\n",
    "- ðŸŒ€ **Kernel-Based Models**\n",
    "- ðŸ§¬ **Neural Network Models**\n",
    "- ðŸŽ¯ **Naive & Simple Baseline Models**\n",
    "\n",
    "ðŸ“ˆ Ushbu yondashuv feature selectionâ€™ning model performansiga boâ€˜lgan  \n",
    "**dastlabki va tezkor taâ€™sirini baholash** imkonini beradi.\n",
    "\n",
    "ðŸŒ Ushbu model oilalari klassik **baseline** yondashuvlardan tortib,  \n",
    "zamonaviy **ensemble** va **kernel-based** modellargacha boâ€˜lgan  \n",
    "keng qamrovli yechimlarni oâ€˜z ichiga oladi.\n",
    "\n",
    "ðŸ” Barcha modellar oâ€˜zaro solishtirish, barqarorlikni baholash  \n",
    "va **eng optimal modelni aniqlash** maqsadida birgalikda sinovdan oâ€˜tkazilgan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70440f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db9abbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\SML_Projects\\SML_hotelBooking_cancelling_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c3b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('data/preprocessed/preprocessed_x_train.csv')\n",
    "x_test = pd.read_csv('data/preprocessed/preprocessed_x_test.csv')\n",
    "\n",
    "y_train = pd.read_csv('data/split/y_train.csv')\n",
    "y_test = pd.read_csv('data/split/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04855fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = df.corr()['is_canceled'].abs()\n",
    "# selected_features = corr[corr >= 0.2].index.tolist()\n",
    "\n",
    "# if 'is_canceled' in selected_features:\n",
    "#     selected_features.remove('is_canceled')\n",
    "\n",
    "# selected_features = selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d485fcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: 9\n"
     ]
    }
   ],
   "source": [
    "train_df = x_train.copy()\n",
    "train_df['is_canceled'] = y_train.squeeze()  \n",
    "\n",
    "corr = train_df.corr()['is_canceled'].abs()\n",
    "\n",
    "selected_features = corr[corr >= 0.2].index.tolist()\n",
    "if 'is_canceled' in selected_features:\n",
    "    selected_features.remove('is_canceled')\n",
    "\n",
    "x_train = x_train[selected_features]\n",
    "x_test  = x_test[selected_features]\n",
    "\n",
    "print(\"Selected features:\", len(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c6f7e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "748f372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42c924b",
   "metadata": {},
   "source": [
    "### ðŸ“Œ 1. Linear Models \n",
    "**Jami: `4ta` algoritm**\n",
    "\n",
    "- **Logistic Regression**\n",
    "- **Ridge Classifier**\n",
    "- **SGD Classifier**\n",
    "- **Passive Aggressive Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "727d4fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR MODELS - CLASSIFICATION (4ta)\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression,\n",
    "    RidgeClassifier,\n",
    "    SGDClassifier,\n",
    "    PassiveAggressiveClassifier\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba2ae9",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b066486c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score: 0.7763212999413687\n",
      "\n",
      "Precision: 0.8271449170872387\n",
      "Recall: 0.5115371753427711\n",
      "F1-score: 0.6321371995316482\n",
      "\n",
      "K-Fold mean: 0.7313118489154671\n",
      "K-Fold std: 0.0018586918305593064\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84     14907\n",
      "           1       0.83      0.51      0.63      8971\n",
      "\n",
      "    accuracy                           0.78     23878\n",
      "   macro avg       0.79      0.72      0.74     23878\n",
      "weighted avg       0.79      0.78      0.76     23878\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "\n",
    "lr_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "lr_precision = precision_score(y_test, y_pred)\n",
    "lr_recall = recall_score(y_test, y_pred)\n",
    "lr_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "lr_scores = cross_val_score(lr, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'Logistic Regression score: {lr_score}')\n",
    "\n",
    "print(f'\\nPrecision: {lr_precision}')\n",
    "print(f'Recall: {lr_recall}')\n",
    "print(f'F1-score: {lr_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", lr_scores.mean())\n",
    "print(\"K-Fold std:\", lr_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b09e56",
   "metadata": {},
   "source": [
    "## RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bb1df52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier score: 0.7701231258899406\n",
      "\n",
      "Precision: 0.8721675929884566\n",
      "Recall: 0.4547987961208338\n",
      "F1-score: 0.5978459960436662\n",
      "\n",
      "K-Fold mean: 0.7160965054441112\n",
      "K-Fold std: 0.003306727101368121\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84     14907\n",
      "           1       0.87      0.45      0.60      8971\n",
      "\n",
      "    accuracy                           0.77     23878\n",
      "   macro avg       0.81      0.71      0.72     23878\n",
      "weighted avg       0.79      0.77      0.75     23878\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_ridge.py:1306: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_ridge.py:1306: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_ridge.py:1306: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_ridge.py:1306: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "ridge = RidgeClassifier()\n",
    "\n",
    "ridge.fit(x_train, y_train)\n",
    "y_pred = ridge.predict(x_test)\n",
    "\n",
    "ridge_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "ridge_precision = precision_score(y_test, y_pred)\n",
    "ridge_recall = recall_score(y_test, y_pred)\n",
    "ridge_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "ridge_scores = cross_val_score(ridge, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'RidgeClassifier score: {ridge_score}')\n",
    "\n",
    "print(f'\\nPrecision: {ridge_precision}')\n",
    "print(f'Recall: {ridge_recall}')\n",
    "print(f'F1-score: {ridge_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", ridge_scores.mean())\n",
    "print(\"K-Fold std:\", ridge_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4692ca",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cb67bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier score: 0.7634223971856939\n",
      "\n",
      "Precision: 0.958586416344561\n",
      "Recall: 0.3870248578753762\n",
      "F1-score: 0.5514174541411896\n",
      "\n",
      "K-Fold mean: 0.6919542341069856\n",
      "K-Fold std: 0.0024454818772081032\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.99      0.84     14907\n",
      "           1       0.96      0.39      0.55      8971\n",
      "\n",
      "    accuracy                           0.76     23878\n",
      "   macro avg       0.84      0.69      0.70     23878\n",
      "weighted avg       0.81      0.76      0.73     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgdc = SGDClassifier()\n",
    "\n",
    "sgdc.fit(x_train, y_train)\n",
    "y_pred = sgdc.predict(x_test)\n",
    "\n",
    "sgdc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "sgdc_precision = precision_score(y_test, y_pred)\n",
    "sgdc_recall = recall_score(y_test, y_pred)\n",
    "sgdc_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "sgdc_scores = cross_val_score(sgdc, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'SGDClassifier score: {sgdc_score}')\n",
    "\n",
    "print(f'\\nPrecision: {sgdc_precision}')\n",
    "print(f'Recall: {sgdc_recall}')\n",
    "print(f'F1-score: {sgdc_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", sgdc_scores.mean())\n",
    "print(\"K-Fold std:\", sgdc_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0263ac2",
   "metadata": {},
   "source": [
    "## PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f79e76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier score: 0.7631711198592847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Precision: 0.910802775024777\n",
      "Recall: 0.4097647976814179\n",
      "F1-score: 0.565234104712847\n",
      "\n",
      "K-Fold mean: 0.6957763777245752\n",
      "K-Fold std: 0.05276325714021124\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.98      0.84     14907\n",
      "           1       0.91      0.41      0.57      8971\n",
      "\n",
      "    accuracy                           0.76     23878\n",
      "   macro avg       0.82      0.69      0.70     23878\n",
      "weighted avg       0.80      0.76      0.74     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pac = PassiveAggressiveClassifier()\n",
    "\n",
    "pac.fit(x_train, y_train)\n",
    "y_pred = pac.predict(x_test)\n",
    "\n",
    "pac_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "pac_precision = precision_score(y_test, y_pred)\n",
    "pac_recall = recall_score(y_test, y_pred)\n",
    "pac_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "pac_scores = cross_val_score(pac, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'SGDClassifier score: {pac_score}')\n",
    "\n",
    "print(f'\\nPrecision: {pac_precision}')\n",
    "print(f'Recall: {pac_recall}')\n",
    "print(f'F1-score: {pac_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", pac_scores.mean())\n",
    "print(\"K-Fold std:\", pac_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1799473a",
   "metadata": {},
   "source": [
    "## ðŸŒ² 2. Tree-Based Models\n",
    "\n",
    "**Jami: `1ta` algoritm**\n",
    "\n",
    "- **Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddd40d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree MODELS (1ta)\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c2f3e",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35fa6471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree score: 0.803207973867158\n",
      "\n",
      "Precision: 0.7968315730961645\n",
      "Recall: 0.6391706610188385\n",
      "F1-score: 0.7093461990474423\n",
      "\n",
      "K-Fold mean: 0.7736248218225641\n",
      "K-Fold std: 0.0017241481656120282\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85     14907\n",
      "           1       0.80      0.64      0.71      8971\n",
      "\n",
      "    accuracy                           0.80     23878\n",
      "   macro avg       0.80      0.77      0.78     23878\n",
      "weighted avg       0.80      0.80      0.80     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=10, min_samples_split=5,random_state=42)\n",
    "\n",
    "dt.fit(x_train, y_train)\n",
    "y_pred = dt.predict(x_test)\n",
    "\n",
    "dt_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "dt_precision = precision_score(y_test, y_pred)\n",
    "dt_recall = recall_score(y_test, y_pred)\n",
    "dt_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "dt_scores = cross_val_score(dt, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'DecisionTree score: {dt_score}')\n",
    "\n",
    "print(f'\\nPrecision: {dt_precision}')\n",
    "print(f'Recall: {dt_recall}')\n",
    "print(f'F1-score: {dt_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", dt_scores.mean())\n",
    "print(\"K-Fold std:\", dt_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dcade",
   "metadata": {},
   "source": [
    "## ðŸ§  3. Ensemble Models\n",
    "\n",
    "**Jami: `12ta` algoritm**\n",
    "\n",
    "### ðŸ“¦ Bagging Family (4ta)\n",
    "- **Random Forest**\n",
    "- **Bagging Classifier**\n",
    "- **Extra Trees**\n",
    "- **Bagged Decision Tree**\n",
    "\n",
    "### ðŸš€ Boosting Family (6ta)\n",
    "- **Gradient Boosting**\n",
    "- **Hist Gradient Boosting**\n",
    "- **AdaBoost**\n",
    "- **CatBoost**\n",
    "- **XGBoost**\n",
    "- **LightGBM**\n",
    "\n",
    "### ðŸ§© Meta-Ensemble Methods\n",
    "- **Stacking**\n",
    "- **Voting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fffcf743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging MODELS (3ta)\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    BaggingClassifier,\n",
    "    ExtraTreesClassifier\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb55d4b",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7870a679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest score: 0.8214255800318284\n",
      "\n",
      "Precision: 0.8195519348268839\n",
      "Recall: 0.6728346895552335\n",
      "F1-score: 0.7389813907933399\n",
      "\n",
      "K-Fold mean: 0.7934872825004867\n",
      "K-Fold std: 0.0016923561249040137\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86     14907\n",
      "           1       0.82      0.67      0.74      8971\n",
      "\n",
      "    accuracy                           0.82     23878\n",
      "   macro avg       0.82      0.79      0.80     23878\n",
      "weighted avg       0.82      0.82      0.82     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=300, max_depth=15, n_jobs=-1, random_state=42)\n",
    "\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "\n",
    "rf_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "rf_precision = precision_score(y_test, y_pred)\n",
    "rf_recall = recall_score(y_test, y_pred)\n",
    "rf_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "rf_scores = cross_val_score(rf, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'RandomForest score: {rf_score}')\n",
    "\n",
    "print(f'\\nPrecision: {rf_precision}')\n",
    "print(f'Recall: {rf_recall}')\n",
    "print(f'F1-score: {rf_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", rf_scores.mean())\n",
    "print(\"K-Fold std:\", rf_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391d25be",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8b21743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_bagging.py:930: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_bagging.py:930: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_bagging.py:930: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_bagging.py:930: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging score: 0.8342407236787001\n",
      "\n",
      "Precision: 0.8101720084148002\n",
      "Recall: 0.7297960093635046\n",
      "F1-score: 0.7678864649307999\n",
      "\n",
      "K-Fold mean: 0.8072515898264215\n",
      "K-Fold std: 0.0003649069454236374\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87     14907\n",
      "           1       0.81      0.73      0.77      8971\n",
      "\n",
      "    accuracy                           0.83     23878\n",
      "   macro avg       0.83      0.81      0.82     23878\n",
      "weighted avg       0.83      0.83      0.83     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bag = BaggingClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "bag.fit(x_train, y_train)\n",
    "y_pred = bag.predict(x_test)\n",
    "\n",
    "bag_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "bag_precision = precision_score(y_test, y_pred)\n",
    "bag_recall = recall_score(y_test, y_pred)\n",
    "bag_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "bag_scores = cross_val_score(bag, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'Bagging score: {bag_score}')\n",
    "\n",
    "print(f'\\nPrecision: {bag_precision}')\n",
    "print(f'Recall: {bag_recall}')\n",
    "print(f'F1-score: {bag_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", bag_scores.mean())\n",
    "print(\"K-Fold std:\", bag_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1097ecd7",
   "metadata": {},
   "source": [
    "## Bagged DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f6ab621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_bagging.py:930: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_bagging.py:930: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_bagging.py:930: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_bagging.py:930: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged DT score: 0.8061814222296675\n",
      "\n",
      "Precision: 0.7976696367374915\n",
      "Recall: 0.6486456359380225\n",
      "F1-score: 0.7154801426287962\n",
      "\n",
      "K-Fold mean: 0.7767033694357822\n",
      "K-Fold std: 0.0015015371465790586\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85     14907\n",
      "           1       0.80      0.65      0.72      8971\n",
      "\n",
      "    accuracy                           0.81     23878\n",
      "   macro avg       0.80      0.77      0.78     23878\n",
      "weighted avg       0.81      0.81      0.80     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bag_dt = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=10),\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "bag_dt.fit(x_train, y_train)\n",
    "y_pred = bag_dt.predict(x_test)\n",
    "\n",
    "bag_dt_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "bag_dt_precision = precision_score(y_test, y_pred)\n",
    "bag_dt_recall = recall_score(y_test, y_pred)\n",
    "bag_dt_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "bag_dt_scores = cross_val_score(bag_dt, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'Bagged DT score: {bag_dt_score}')\n",
    "\n",
    "print(f'\\nPrecision: {bag_dt_precision}')\n",
    "print(f'Recall: {bag_dt_recall}')\n",
    "print(f'F1-score: {bag_dt_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", bag_dt_scores.mean())\n",
    "print(\"K-Fold std:\", bag_dt_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeae304",
   "metadata": {},
   "source": [
    "## ExtraTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "773f0525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees score: 0.8001507663958456\n",
      "\n",
      "Precision: 0.8427755102040816\n",
      "Recall: 0.5754096533273882\n",
      "F1-score: 0.6838897721250663\n",
      "\n",
      "K-Fold mean: 0.7630471899041472\n",
      "K-Fold std: 0.0018437750061848688\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.85     14907\n",
      "           1       0.84      0.58      0.68      8971\n",
      "\n",
      "    accuracy                           0.80     23878\n",
      "   macro avg       0.81      0.76      0.77     23878\n",
      "weighted avg       0.81      0.80      0.79     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=300, max_depth=15, n_jobs=-1, random_state=42)\n",
    "\n",
    "et.fit(x_train, y_train)\n",
    "y_pred = et.predict(x_test)\n",
    "\n",
    "et_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "et_precision = precision_score(y_test, y_pred)\n",
    "et_recall = recall_score(y_test, y_pred)\n",
    "et_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "et_scores = cross_val_score(et, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'ExtraTrees score: {et_score}')\n",
    "\n",
    "print(f'\\nPrecision: {et_precision}')\n",
    "print(f'Recall: {et_recall}')\n",
    "print(f'F1-score: {et_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", et_scores.mean())\n",
    "print(\"K-Fold std:\", et_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "257ab8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting MODELS (6ta)\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    AdaBoostClassifier\n",
    ")\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beccef9",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "914075cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting score: 0.8000251277326409\n",
      "\n",
      "Precision: 0.8098050797401063\n",
      "Recall: 0.6113030877271207\n",
      "F1-score: 0.6966905926443498\n",
      "\n",
      "K-Fold mean: 0.7700598970522781\n",
      "K-Fold std: 0.0006257055705719118\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85     14907\n",
      "           1       0.81      0.61      0.70      8971\n",
      "\n",
      "    accuracy                           0.80     23878\n",
      "   macro avg       0.80      0.76      0.77     23878\n",
      "weighted avg       0.80      0.80      0.79     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=300, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "\n",
    "gb.fit(x_train, y_train)\n",
    "y_pred = gb.predict(x_test)\n",
    "\n",
    "gb_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "gb_precision = precision_score(y_test, y_pred)\n",
    "gb_recall = recall_score(y_test, y_pred)\n",
    "gb_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "gb_scores = cross_val_score(gb, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'GradientBoosting score: {gb_score}')\n",
    "\n",
    "print(f'\\nPrecision: {gb_precision}')\n",
    "print(f'Recall: {gb_recall}')\n",
    "print(f'F1-score: {gb_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", gb_scores.mean())\n",
    "print(\"K-Fold std:\", gb_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2735f3bb",
   "metadata": {},
   "source": [
    "## Hist Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7f722b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoosting score: 0.8129659100427171\n",
      "\n",
      "Precision: 0.8154320123232041\n",
      "Recall: 0.64909151711069\n",
      "F1-score: 0.7228152929493545\n",
      "\n",
      "K-Fold mean: 0.7861455900344771\n",
      "K-Fold std: 0.0009278476048832347\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86     14907\n",
      "           1       0.82      0.65      0.72      8971\n",
      "\n",
      "    accuracy                           0.81     23878\n",
      "   macro avg       0.81      0.78      0.79     23878\n",
      "weighted avg       0.81      0.81      0.81     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hgb = HistGradientBoostingClassifier(max_iter=300, learning_rate=0.05, max_depth=7, random_state=42)\n",
    "\n",
    "hgb.fit(x_train, y_train)\n",
    "y_pred = hgb.predict(x_test)\n",
    "\n",
    "hgb_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "hgb_precision = precision_score(y_test, y_pred)\n",
    "hgb_recall = recall_score(y_test, y_pred)\n",
    "hgb_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "hgb_scores = cross_val_score(hgb, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'HistGradientBoosting score: {hgb_score}')\n",
    "\n",
    "print(f'\\nPrecision: {hgb_precision}')\n",
    "print(f'Recall: {hgb_recall}')\n",
    "print(f'F1-score: {hgb_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", hgb_scores.mean())\n",
    "print(\"K-Fold std:\", hgb_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8507042",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87c9a404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost score: 0.8210486640422145\n",
      "\n",
      "Precision: 0.8267037552155772\n",
      "Recall: 0.6625794225838814\n",
      "F1-score: 0.7355980446754532\n",
      "\n",
      "K-Fold mean: 0.7923904380804103\n",
      "K-Fold std: 0.0012400459970718701\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.86     14907\n",
      "           1       0.83      0.66      0.74      8971\n",
      "\n",
      "    accuracy                           0.82     23878\n",
      "   macro avg       0.82      0.79      0.80     23878\n",
      "weighted avg       0.82      0.82      0.82     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(x_train, y_train)\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "xgb_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "xgb_precision = precision_score(y_test, y_pred)\n",
    "xgb_recall = recall_score(y_test, y_pred)\n",
    "xgb_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "xgb_scores = cross_val_score(xgb, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'XGBoost score: {xgb_score}')\n",
    "\n",
    "print(f'\\nPrecision: {xgb_precision}')\n",
    "print(f'Recall: {xgb_recall}')\n",
    "print(f'F1-score: {xgb_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", xgb_scores.mean())\n",
    "print(\"K-Fold std:\", xgb_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139d705b",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7be85f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost score: 0.7585643688751151\n",
      "\n",
      "Precision: 0.9878271454656117\n",
      "Recall: 0.36183257161966337\n",
      "F1-score: 0.5296565228032961\n",
      "\n",
      "K-Fold mean: 0.6796073454535715\n",
      "K-Fold std: 0.0029227340427064657\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84     14907\n",
      "           1       0.99      0.36      0.53      8971\n",
      "\n",
      "    accuracy                           0.76     23878\n",
      "   macro avg       0.85      0.68      0.68     23878\n",
      "weighted avg       0.82      0.76      0.72     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostClassifier(n_estimators=300, learning_rate=0.05, random_state=42)\n",
    "\n",
    "ab.fit(x_train, y_train)\n",
    "y_pred = ab.predict(x_test)\n",
    "\n",
    "ab_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "ab_precision = precision_score(y_test, y_pred)\n",
    "ab_recall = recall_score(y_test, y_pred)\n",
    "ab_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "ab_scores = cross_val_score(ab, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'AdaBoost score: {ab_score}')\n",
    "\n",
    "print(f'\\nPrecision: {ab_precision}')\n",
    "print(f'Recall: {ab_recall}')\n",
    "print(f'F1-score: {ab_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", ab_scores.mean())\n",
    "print(\"K-Fold std:\", ab_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e5399a",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9600304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 35253, number of negative: 60259\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 911\n",
      "[LightGBM] [Info] Number of data points in the train set: 95512, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369095 -> initscore=-0.536101\n",
      "[LightGBM] [Info] Start training from score -0.536101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 23553, number of negative: 40121\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 900\n",
      "[LightGBM] [Info] Number of data points in the train set: 63674, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369900 -> initscore=-0.532647\n",
      "[LightGBM] [Info] Start training from score -0.532647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 23477, number of negative: 40198\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 902\n",
      "[LightGBM] [Info] Number of data points in the train set: 63675, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368700 -> initscore=-0.537796\n",
      "[LightGBM] [Info] Start training from score -0.537796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 23476, number of negative: 40199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 903\n",
      "[LightGBM] [Info] Number of data points in the train set: 63675, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368685 -> initscore=-0.537863\n",
      "[LightGBM] [Info] Start training from score -0.537863\n",
      "\n",
      "LightGBM score: 0.8222631711198592\n",
      "\n",
      "Precision: 0.8324658883105922\n",
      "Recall: 0.6596811949615428\n",
      "F1-score: 0.7360696517412936\n",
      "\n",
      "K-Fold mean: 0.7935493841977183\n",
      "K-Fold std: 0.0014917540251880876\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87     14907\n",
      "           1       0.83      0.66      0.74      8971\n",
      "\n",
      "    accuracy                           0.82     23878\n",
      "   macro avg       0.83      0.79      0.80     23878\n",
      "weighted avg       0.82      0.82      0.82     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=31, subsample=0.8, colsample_bytree=0.8, random_state=42)\n",
    "\n",
    "lgbm.fit(x_train, y_train)\n",
    "y_pred = lgbm.predict(x_test)\n",
    "\n",
    "lgbm_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "lgbm_precision = precision_score(y_test, y_pred)\n",
    "lgbm_recall = recall_score(y_test, y_pred)\n",
    "lgbm_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'\\nLightGBM score: {lgbm_score}')\n",
    "\n",
    "print(f'\\nPrecision: {lgbm_precision}')\n",
    "print(f'Recall: {lgbm_recall}')\n",
    "print(f'F1-score: {lgbm_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", lgbm_scores.mean())\n",
    "print(\"K-Fold std:\", lgbm_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32804fe2",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2c6fd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost score: 0.8140128989027556\n",
      "\n",
      "Precision: 0.8168718522663683\n",
      "Recall: 0.6508750418013599\n",
      "F1-score: 0.7244866306842856\n",
      "\n",
      "K-Fold mean: 0.7872613387897872\n",
      "K-Fold std: 0.0025251954586664434\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86     14907\n",
      "           1       0.82      0.65      0.72      8971\n",
      "\n",
      "    accuracy                           0.81     23878\n",
      "   macro avg       0.81      0.78      0.79     23878\n",
      "weighted avg       0.81      0.81      0.81     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(iterations=500, depth=8,learning_rate=0.05, verbose=False, random_state=42)\n",
    "\n",
    "cat.fit(x_train, y_train)\n",
    "y_pred = cat.predict(x_test)\n",
    "\n",
    "cat_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "cat_precision = precision_score(y_test, y_pred)\n",
    "cat_recall = recall_score(y_test, y_pred)\n",
    "cat_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "cat_scores = cross_val_score(cat, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'CatBoost score: {cat_score}')\n",
    "\n",
    "print(f'\\nPrecision: {cat_precision}')\n",
    "print(f'Recall: {cat_recall}')\n",
    "print(f'F1-score: {cat_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", cat_scores.mean())\n",
    "print(\"K-Fold std:\", cat_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48c9ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking & Voting MODELS\n",
    "from sklearn.ensemble import (\n",
    "    StackingClassifier,\n",
    "    VotingClassifier\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dcf130",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8789a8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking score: 0.8388474746628696\n",
      "\n",
      "Precision: 0.8295381448604142\n",
      "Recall: 0.7187604503399844\n",
      "F1-score: 0.7701863354037267\n",
      "\n",
      "K-Fold mean: 0.8092812110844694\n",
      "K-Fold std: 0.0006818905819641628\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.88     14907\n",
      "           1       0.83      0.72      0.77      8971\n",
      "\n",
      "    accuracy                           0.84     23878\n",
      "   macro avg       0.84      0.81      0.82     23878\n",
      "weighted avg       0.84      0.84      0.84     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base1 = RandomForestClassifier(random_state=42)\n",
    "base2 = ExtraTreesClassifier(random_state=42)\n",
    "base3 = LogisticRegression()\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', base1),\n",
    "        ('et', base2),\n",
    "        ('lr', base3)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "stacking.fit(x_train, y_train)\n",
    "y_pred = stacking.predict(x_test)\n",
    "\n",
    "stacking_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "stacking_precision = precision_score(y_test, y_pred)\n",
    "stacking_recall = recall_score(y_test, y_pred)\n",
    "stacking_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "stacking_scores = cross_val_score(stacking, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'Stacking score: {stacking_score}')\n",
    "\n",
    "print(f'\\nPrecision: {stacking_precision}')\n",
    "print(f'Recall: {stacking_recall}')\n",
    "print(f'F1-score: {stacking_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", stacking_scores.mean())\n",
    "print(\"K-Fold std:\", stacking_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ad4b9",
   "metadata": {},
   "source": [
    "## Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52869623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting score: 0.8375492084764218\n",
      "\n",
      "Precision: 0.8292809105018106\n",
      "Recall: 0.7147475197859771\n",
      "F1-score: 0.7677662695324193\n",
      "\n",
      "K-Fold mean: 0.8056172620340182\n",
      "K-Fold std: 0.0006852827206368065\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.88     14907\n",
      "           1       0.83      0.71      0.77      8971\n",
      "\n",
      "    accuracy                           0.84     23878\n",
      "   macro avg       0.84      0.81      0.82     23878\n",
      "weighted avg       0.84      0.84      0.83     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestClassifier(random_state=42)\n",
    "model2 = ExtraTreesClassifier(random_state=42)\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "hard_voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', model1),\n",
    "        ('et', model2),\n",
    "        ('lr', model3)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "hard_voting.fit(x_train, y_train)\n",
    "y_pred = hard_voting.predict(x_test)\n",
    "\n",
    "hard_voting_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "hard_voting_precision = precision_score(y_test, y_pred)\n",
    "hard_voting_recall = recall_score(y_test, y_pred)\n",
    "hard_voting_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "hard_voting_scores = cross_val_score(hard_voting, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'Hard Voting score: {hard_voting_score}')\n",
    "\n",
    "print(f'\\nPrecision: {hard_voting_precision}')\n",
    "print(f'Recall: {hard_voting_recall}')\n",
    "print(f'F1-score: {hard_voting_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", hard_voting_scores.mean())\n",
    "print(\"K-Fold std:\", hard_voting_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a191e2",
   "metadata": {},
   "source": [
    "## Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15157c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Voting score: 0.8388055951084681\n",
      "\n",
      "Precision: 0.8365308804204994\n",
      "Recall: 0.7096198863003009\n",
      "F1-score: 0.7678668355346481\n",
      "\n",
      "K-Fold mean: 0.8066040180682709\n",
      "K-Fold std: 0.000337418062282595\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88     14907\n",
      "           1       0.84      0.71      0.77      8971\n",
      "\n",
      "    accuracy                           0.84     23878\n",
      "   macro avg       0.84      0.81      0.82     23878\n",
      "weighted avg       0.84      0.84      0.84     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestClassifier(random_state=42)\n",
    "model2 = ExtraTreesClassifier(random_state=42)\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "soft_voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', model1),\n",
    "        ('et', model2),\n",
    "        ('lr', model3)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "soft_voting.fit(x_train, y_train)\n",
    "y_pred = soft_voting.predict(x_test)\n",
    "\n",
    "soft_voting_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "soft_voting_precision = precision_score(y_test, y_pred)\n",
    "soft_voting_recall = recall_score(y_test, y_pred)\n",
    "soft_voting_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "soft_voting_scores = cross_val_score(soft_voting, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'Soft Voting score: {soft_voting_score}')\n",
    "\n",
    "print(f'\\nPrecision: {soft_voting_precision}')\n",
    "print(f'Recall: {soft_voting_recall}')\n",
    "print(f'F1-score: {soft_voting_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", soft_voting_scores.mean())\n",
    "print(\"K-Fold std:\", soft_voting_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc1f64",
   "metadata": {},
   "source": [
    "## ðŸ‘¥ 4. Neighbors-Based Models\n",
    "\n",
    "**Jami: `2ta` algoritm**\n",
    "\n",
    "- **K-Nearest Neighbors (KNN) Classifier**\n",
    "- **Radius Neighbors Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d6430c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keighbors MODELS (2ta)\n",
    "from sklearn.neighbors import (\n",
    "    KNeighborsClassifier,\n",
    "    RadiusNeighborsClassifier,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1033a4e1",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa3d3de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score: 0.7941619901164252\n",
      "\n",
      "Precision: 0.7180645161290322\n",
      "Recall: 0.7443986177683647\n",
      "F1-score: 0.7309944721142795\n",
      "\n",
      "K-Fold mean: 0.7752889299042335\n",
      "K-Fold std: 0.006541059933180298\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83     14907\n",
      "           1       0.72      0.74      0.73      8971\n",
      "\n",
      "    accuracy                           0.79     23878\n",
      "   macro avg       0.78      0.78      0.78     23878\n",
      "weighted avg       0.80      0.79      0.79     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "\n",
    "knn_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "knn_precision = precision_score(y_test, y_pred)\n",
    "knn_recall = recall_score(y_test, y_pred)\n",
    "knn_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "knn_scores = cross_val_score(knn, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'KNN score: {knn_score}')\n",
    "\n",
    "print(f'\\nPrecision: {knn_precision}')\n",
    "print(f'Recall: {knn_recall}')\n",
    "print(f'F1-score: {knn_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", knn_scores.mean())\n",
    "print(\"K-Fold std:\", knn_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b4a348",
   "metadata": {},
   "source": [
    "## ðŸ“ 5. Support Vector Machine (SVM) Models\n",
    "\n",
    "**Jami: `1ta` algoritm**\n",
    "\n",
    "- **Support Vector Classifier (SVC)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "477d20bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC score: 0.782854510428009\n",
      "\n",
      "Precision: 0.8176174496644295\n",
      "Recall: 0.5431947386021625\n",
      "F1-score: 0.6527359185587034\n",
      "\n",
      "K-Fold mean: 0.7423968605269206\n",
      "K-Fold std: 0.002030008178460673\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84     14907\n",
      "           1       0.82      0.54      0.65      8971\n",
      "\n",
      "    accuracy                           0.78     23878\n",
      "   macro avg       0.79      0.74      0.75     23878\n",
      "weighted avg       0.79      0.78      0.77     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svr = SVC(kernel='rbf', C=20.0)\n",
    "\n",
    "svr.fit(x_train, y_train)\n",
    "y_pred = svr.predict(x_test)\n",
    "\n",
    "svr_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "svr_precision = precision_score(y_test, y_pred)\n",
    "svr_recall = recall_score(y_test, y_pred)\n",
    "svr_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "svr_scores = cross_val_score(svr, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'SVC score: {svr_score}')\n",
    "\n",
    "print(f'\\nPrecision: {svr_precision}')\n",
    "print(f'Recall: {svr_recall}')\n",
    "print(f'F1-score: {svr_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", svr_scores.mean())\n",
    "print(\"K-Fold std:\", svr_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34a66fe",
   "metadata": {},
   "source": [
    "## ðŸ§¬ 7. Neural Network Models\n",
    "\n",
    "**Jami: `1ta` algoritm**\n",
    "\n",
    "- **Multi-Layer Perceptron (MLP) Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5ba51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network MODEL\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8266dd21",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2d16cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier score: 0.7932406399195913\n",
      "\n",
      "Precision: 0.8176377952755906\n",
      "Recall: 0.5787537621223944\n",
      "F1-score: 0.6777625481365446\n",
      "\n",
      "K-Fold mean: 0.769909351995634\n",
      "K-Fold std: 0.00477825112052719\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.85     14907\n",
      "           1       0.82      0.58      0.68      8971\n",
      "\n",
      "    accuracy                           0.79     23878\n",
      "   macro avg       0.80      0.75      0.76     23878\n",
      "weighted avg       0.80      0.79      0.78     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlpc = MLPClassifier(hidden_layer_sizes=(128, 64), activation=\"relu\", max_iter=300, random_state=42)\n",
    "\n",
    "mlpc.fit(x_train, y_train)\n",
    "y_pred = mlpc.predict(x_test)\n",
    "\n",
    "mlpc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "mlpc_precision = precision_score(y_test, y_pred)\n",
    "mlpc_recall = recall_score(y_test, y_pred)\n",
    "mlpc_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "mlpc_scores = cross_val_score(mlpc, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'MLPClassifier score: {mlpc_score}')\n",
    "\n",
    "print(f'\\nPrecision: {mlpc_precision}')\n",
    "print(f'Recall: {mlpc_recall}')\n",
    "print(f'F1-score: {mlpc_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", mlpc_scores.mean())\n",
    "print(\"K-Fold std:\", mlpc_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c4b4a",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ 8. Naive & Simple Baseline Models\n",
    "\n",
    "**Jami: `1ta` algoritm**\n",
    "\n",
    "- **Dummy Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e99b0e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Baseline MODEL\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36f854a",
   "metadata": {},
   "source": [
    "## DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58c2455d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier score: 0.6242985174637742\n",
      "\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "\n",
      "K-Fold mean: 0.38684320260727606\n",
      "K-Fold std: 0.0004277210010969743\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77     14907\n",
      "           1       0.00      0.00      0.00      8971\n",
      "\n",
      "    accuracy                           0.62     23878\n",
      "   macro avg       0.31      0.50      0.38     23878\n",
      "weighted avg       0.39      0.62      0.48     23878\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier()\n",
    "\n",
    "dummy.fit(x_train, y_train)\n",
    "y_pred = dummy.predict(x_test)\n",
    "\n",
    "dummy_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "dummy_precision = precision_score(y_test, y_pred)\n",
    "dummy_recall = recall_score(y_test, y_pred)\n",
    "dummy_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "dummy_scores = cross_val_score(dummy, x_train, y_train, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'DummyClassifier score: {dummy_score}')\n",
    "\n",
    "print(f'\\nPrecision: {dummy_precision}')\n",
    "print(f'Recall: {dummy_recall}')\n",
    "print(f'F1-score: {dummy_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", dummy_scores.mean())\n",
    "print(\"K-Fold std:\", dummy_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c08726e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                Comparison with Filter Method                                 </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Algorithm            </span>â”ƒ<span style=\"font-weight: bold\"> Accuracy </span>â”ƒ<span style=\"font-weight: bold\"> Precision </span>â”ƒ<span style=\"font-weight: bold\"> Recall </span>â”ƒ<span style=\"font-weight: bold\"> F1-score </span>â”ƒ<span style=\"font-weight: bold\"> K-Fold mean </span>â”ƒ<span style=\"font-weight: bold\"> K-Fold std </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">KNN</span>                  â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.79</span>     â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.72</span>      â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.74</span>   â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.73</span>     â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.78</span>        â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.01</span>       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Bagging              â”‚ 0.83     â”‚ 0.81      â”‚ 0.73   â”‚ 0.77     â”‚ 0.81        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Stacking             â”‚ 0.84     â”‚ 0.83      â”‚ 0.72   â”‚ 0.77     â”‚ 0.81        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Hard Voting          â”‚ 0.84     â”‚ 0.83      â”‚ 0.71   â”‚ 0.77     â”‚ 0.81        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Soft Voting          â”‚ 0.84     â”‚ 0.84      â”‚ 0.71   â”‚ 0.77     â”‚ 0.81        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ RandomForest         â”‚ 0.82     â”‚ 0.82      â”‚ 0.67   â”‚ 0.74     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ XGBoost              â”‚ 0.82     â”‚ 0.83      â”‚ 0.66   â”‚ 0.74     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ LGBMClassifier       â”‚ 0.82     â”‚ 0.83      â”‚ 0.66   â”‚ 0.74     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ CatBoost             â”‚ 0.81     â”‚ 0.82      â”‚ 0.65   â”‚ 0.72     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ HistGradientBoosting â”‚ 0.81     â”‚ 0.82      â”‚ 0.65   â”‚ 0.72     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Bagged DT            â”‚ 0.81     â”‚ 0.80      â”‚ 0.65   â”‚ 0.72     â”‚ 0.78        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ DecisionTree         â”‚ 0.80     â”‚ 0.80      â”‚ 0.64   â”‚ 0.71     â”‚ 0.77        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ GradientBoosting     â”‚ 0.80     â”‚ 0.81      â”‚ 0.61   â”‚ 0.70     â”‚ 0.77        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ MLPC                 â”‚ 0.79     â”‚ 0.82      â”‚ 0.58   â”‚ 0.68     â”‚ 0.77        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ ExtraTrees           â”‚ 0.80     â”‚ 0.84      â”‚ 0.58   â”‚ 0.68     â”‚ 0.76        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ SVC                  â”‚ 0.78     â”‚ 0.82      â”‚ 0.54   â”‚ 0.65     â”‚ 0.74        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Logistic Regression  â”‚ 0.78     â”‚ 0.83      â”‚ 0.51   â”‚ 0.63     â”‚ 0.73        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ RidgeClassifier      â”‚ 0.77     â”‚ 0.87      â”‚ 0.45   â”‚ 0.60     â”‚ 0.72        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Passive Aggressive   â”‚ 0.76     â”‚ 0.91      â”‚ 0.41   â”‚ 0.57     â”‚ 0.70        â”‚ 0.05       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ SGDC                 â”‚ 0.76     â”‚ 0.96      â”‚ 0.39   â”‚ 0.55     â”‚ 0.69        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ AdaBoost             â”‚ 0.76     â”‚ 0.99      â”‚ 0.36   â”‚ 0.53     â”‚ 0.68        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">DummyClassifier</span>      â”‚ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.62</span>     â”‚ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>      â”‚ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>   â”‚ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>     â”‚ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.39</span>        â”‚ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                Comparison with Filter Method                                 \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mAlgorithm           \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mAccuracy\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mPrecision\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mRecall\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mF1-score\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mK-Fold mean\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mK-Fold std\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ \u001b[1;32mKNN\u001b[0m                  â”‚ \u001b[1;32m0.79\u001b[0m     â”‚ \u001b[1;32m0.72\u001b[0m      â”‚ \u001b[1;32m0.74\u001b[0m   â”‚ \u001b[1;32m0.73\u001b[0m     â”‚ \u001b[1;32m0.78\u001b[0m        â”‚ \u001b[1;32m0.01\u001b[0m       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Bagging              â”‚ 0.83     â”‚ 0.81      â”‚ 0.73   â”‚ 0.77     â”‚ 0.81        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Stacking             â”‚ 0.84     â”‚ 0.83      â”‚ 0.72   â”‚ 0.77     â”‚ 0.81        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Hard Voting          â”‚ 0.84     â”‚ 0.83      â”‚ 0.71   â”‚ 0.77     â”‚ 0.81        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Soft Voting          â”‚ 0.84     â”‚ 0.84      â”‚ 0.71   â”‚ 0.77     â”‚ 0.81        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ RandomForest         â”‚ 0.82     â”‚ 0.82      â”‚ 0.67   â”‚ 0.74     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ XGBoost              â”‚ 0.82     â”‚ 0.83      â”‚ 0.66   â”‚ 0.74     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ LGBMClassifier       â”‚ 0.82     â”‚ 0.83      â”‚ 0.66   â”‚ 0.74     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ CatBoost             â”‚ 0.81     â”‚ 0.82      â”‚ 0.65   â”‚ 0.72     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ HistGradientBoosting â”‚ 0.81     â”‚ 0.82      â”‚ 0.65   â”‚ 0.72     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Bagged DT            â”‚ 0.81     â”‚ 0.80      â”‚ 0.65   â”‚ 0.72     â”‚ 0.78        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ DecisionTree         â”‚ 0.80     â”‚ 0.80      â”‚ 0.64   â”‚ 0.71     â”‚ 0.77        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ GradientBoosting     â”‚ 0.80     â”‚ 0.81      â”‚ 0.61   â”‚ 0.70     â”‚ 0.77        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ MLPC                 â”‚ 0.79     â”‚ 0.82      â”‚ 0.58   â”‚ 0.68     â”‚ 0.77        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ ExtraTrees           â”‚ 0.80     â”‚ 0.84      â”‚ 0.58   â”‚ 0.68     â”‚ 0.76        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ SVC                  â”‚ 0.78     â”‚ 0.82      â”‚ 0.54   â”‚ 0.65     â”‚ 0.74        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Logistic Regression  â”‚ 0.78     â”‚ 0.83      â”‚ 0.51   â”‚ 0.63     â”‚ 0.73        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ RidgeClassifier      â”‚ 0.77     â”‚ 0.87      â”‚ 0.45   â”‚ 0.60     â”‚ 0.72        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Passive Aggressive   â”‚ 0.76     â”‚ 0.91      â”‚ 0.41   â”‚ 0.57     â”‚ 0.70        â”‚ 0.05       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ SGDC                 â”‚ 0.76     â”‚ 0.96      â”‚ 0.39   â”‚ 0.55     â”‚ 0.69        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ AdaBoost             â”‚ 0.76     â”‚ 0.99      â”‚ 0.36   â”‚ 0.53     â”‚ 0.68        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ \u001b[1;31mDummyClassifier\u001b[0m      â”‚ \u001b[1;31m0.62\u001b[0m     â”‚ \u001b[1;31m0.00\u001b[0m      â”‚ \u001b[1;31m0.00\u001b[0m   â”‚ \u001b[1;31m0.00\u001b[0m     â”‚ \u001b[1;31m0.39\u001b[0m        â”‚ \u001b[1;31m0.00\u001b[0m       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "\n",
    "results = [\n",
    "    # Linear Family\n",
    "    ['Logistic Regression', lr_score, lr_precision, lr_recall, lr_f1, lr_scores.mean(), lr_scores.std()],\n",
    "    ['RidgeClassifier', ridge_score, ridge_precision, ridge_recall, ridge_f1, ridge_scores.mean(), ridge_scores.std()],\n",
    "    ['SGDC', sgdc_score, sgdc_precision, sgdc_recall, sgdc_f1, sgdc_scores.mean(), sgdc_scores.std()],\n",
    "    ['Passive Aggressive', pac_score, pac_precision, pac_recall, pac_f1, pac_scores.mean(), pac_scores.std()],\n",
    "\n",
    "    # Tree-Based Family\n",
    "    ['DecisionTree', dt_score, dt_precision, dt_recall, dt_f1, dt_scores.mean(), dt_scores.std()],\n",
    "\n",
    "    # Bagging Family\n",
    "    ['RandomForest', rf_score, rf_precision, rf_recall, rf_f1, rf_scores.mean(), rf_scores.std()],\n",
    "    ['Bagging', bag_score, bag_precision, bag_recall, bag_f1, bag_scores.mean(), bag_scores.std()],\n",
    "    ['Bagged DT', bag_dt_score, bag_dt_precision, bag_dt_recall, bag_dt_f1, bag_dt_scores.mean(), bag_dt_scores.std()],\n",
    "    ['ExtraTrees', et_score, et_precision, et_recall, et_f1, et_scores.mean(), et_scores.std()],\n",
    "\n",
    "    # Boosting Family\n",
    "    ['GradientBoosting', gb_score, gb_precision, gb_recall, gb_f1, gb_scores.mean(), gb_scores.std()],\n",
    "    ['HistGradientBoosting', hgb_score, hgb_precision, hgb_recall, hgb_f1, hgb_scores.mean(), hgb_scores.std()],\n",
    "    ['XGBoost', xgb_score, xgb_precision, xgb_recall, xgb_f1, xgb_scores.mean(), xgb_scores.std()],\n",
    "    ['AdaBoost', ab_score, ab_precision, ab_recall, ab_f1, ab_scores.mean(), ab_scores.std()],\n",
    "    ['LGBMClassifier', lgbm_score, lgbm_precision, lgbm_recall, lgbm_f1, lgbm_scores.mean(), lgbm_scores.std()],\n",
    "    ['CatBoost', cat_score, cat_precision, cat_recall, cat_f1, cat_scores.mean(), cat_scores.std()],\n",
    "\n",
    "    # Stacking & Voting Family\n",
    "    ['Hard Voting', hard_voting_score, hard_voting_precision, hard_voting_recall, hard_voting_f1, hard_voting_scores.mean(), hard_voting_scores.std()],\n",
    "    ['Soft Voting', soft_voting_score, soft_voting_precision, soft_voting_recall, soft_voting_f1, soft_voting_scores.mean(), soft_voting_scores.std()],\n",
    "    ['Stacking', stacking_score, stacking_precision, stacking_recall, stacking_f1, stacking_scores.mean(), stacking_scores.std()],\n",
    "\n",
    "    # Neighbors Family\n",
    "    ['KNN', knn_score, knn_precision, knn_recall, knn_f1, knn_scores.mean(), knn_scores.std()],\n",
    "\n",
    "    # SVM Family\n",
    "    ['SVC', svr_score, svr_precision, svr_recall, svr_f1, svr_scores.mean(), svr_scores.std()],\n",
    "\n",
    "    # Neural Network Family\n",
    "    ['MLPC', mlpc_score, mlpc_precision, mlpc_recall, mlpc_f1, mlpc_scores.mean(), mlpc_scores.std()],\n",
    "\n",
    "    # Naive & Simple Family\n",
    "    ['DummyClassifier', dummy_score, dummy_precision, dummy_recall, dummy_f1, dummy_scores.mean(), dummy_scores.std()],\n",
    "]\n",
    "\n",
    "result_sorted = sorted(results, key=lambda i: i[3], reverse=True)\n",
    "\n",
    "best_model = max(results, key=lambda x: x[3])\n",
    "worst_model = min(results, key=lambda x: x[3])\n",
    "\n",
    "table = Table(title=\"Comparison with Filter Method\", show_lines=True)\n",
    "table.add_column(\"Algorithm\")\n",
    "table.add_column(\"Accuracy\")\n",
    "table.add_column(\"Precision\")\n",
    "table.add_column(\"Recall\")\n",
    "table.add_column(\"F1-score\")\n",
    "table.add_column(\"K-Fold mean\")\n",
    "table.add_column(\"K-Fold std\")\n",
    "\n",
    "for row in result_sorted:\n",
    "    algo, acc, presicion, recall, f1, kmean, kstd = row\n",
    "\n",
    "    if row == best_model:\n",
    "        table.add_row(\n",
    "            f\"[bold green]{algo}[/bold green]\",\n",
    "            f\"[bold green]{acc:.2f}[/bold green]\",\n",
    "            f\"[bold green]{presicion:.2f}[/bold green]\",\n",
    "            f\"[bold green]{recall:.2f}[/bold green]\",\n",
    "            f\"[bold green]{f1:.2f}[/bold green]\",\n",
    "            f\"[bold green]{kmean:.2f}[/bold green]\",\n",
    "            f\"[bold green]{kstd:.2f}[/bold green]\",\n",
    "        )\n",
    "    elif row == worst_model:\n",
    "        table.add_row(\n",
    "            f\"[bold red]{algo}[/bold red]\",\n",
    "            f\"[bold red]{acc:.2f}[/bold red]\",\n",
    "            f\"[bold red]{presicion:.2f}[/bold red]\",\n",
    "            f\"[bold red]{recall:.2f}[/bold red]\",\n",
    "            f\"[bold red]{f1:.2f}[/bold red]\",\n",
    "            f\"[bold red]{kmean:.2f}[/bold red]\",\n",
    "            f\"[bold red]{kstd:.2f}[/bold red]\",\n",
    "        )\n",
    "    else:\n",
    "        table.add_row(algo, f\"{acc:.2f}\", f\"{presicion:.2f}\", f\"{recall:.2f}\", f\"{f1:.2f}\", f\"{kmean:.2f}\", f\"{kstd:.2f}\")\n",
    "\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5c769ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                Comparison with Filter Method                                 </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Algorithm            </span>â”ƒ<span style=\"font-weight: bold\"> Accuracy </span>â”ƒ<span style=\"font-weight: bold\"> Precision </span>â”ƒ<span style=\"font-weight: bold\"> Recall </span>â”ƒ<span style=\"font-weight: bold\"> F1-score </span>â”ƒ<span style=\"font-weight: bold\"> K-Fold mean </span>â”ƒ<span style=\"font-weight: bold\"> K-Fold std </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">KNN</span>                  â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.79</span>     â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.72</span>      â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.74</span>   â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.73</span>     â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.78</span>        â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.01</span>       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Bagging              â”‚ 0.83     â”‚ 0.81      â”‚ 0.73   â”‚ 0.77     â”‚ 0.81        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Stacking             â”‚ 0.84     â”‚ 0.83      â”‚ 0.72   â”‚ 0.77     â”‚ 0.81        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Hard Voting          â”‚ 0.84     â”‚ 0.83      â”‚ 0.71   â”‚ 0.77     â”‚ 0.81        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Soft Voting          â”‚ 0.84     â”‚ 0.84      â”‚ 0.71   â”‚ 0.77     â”‚ 0.81        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ RandomForest         â”‚ 0.82     â”‚ 0.82      â”‚ 0.67   â”‚ 0.74     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ XGBoost              â”‚ 0.82     â”‚ 0.83      â”‚ 0.66   â”‚ 0.74     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ LGBMClassifier       â”‚ 0.82     â”‚ 0.83      â”‚ 0.66   â”‚ 0.74     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ CatBoost             â”‚ 0.81     â”‚ 0.82      â”‚ 0.65   â”‚ 0.72     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ HistGradientBoosting â”‚ 0.81     â”‚ 0.82      â”‚ 0.65   â”‚ 0.72     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Bagged DT            â”‚ 0.81     â”‚ 0.80      â”‚ 0.65   â”‚ 0.72     â”‚ 0.78        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ DecisionTree         â”‚ 0.80     â”‚ 0.80      â”‚ 0.64   â”‚ 0.71     â”‚ 0.77        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ GradientBoosting     â”‚ 0.80     â”‚ 0.81      â”‚ 0.61   â”‚ 0.70     â”‚ 0.77        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ MLPC                 â”‚ 0.79     â”‚ 0.82      â”‚ 0.58   â”‚ 0.68     â”‚ 0.77        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ ExtraTrees           â”‚ 0.80     â”‚ 0.84      â”‚ 0.58   â”‚ 0.68     â”‚ 0.76        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ SVC                  â”‚ 0.78     â”‚ 0.82      â”‚ 0.54   â”‚ 0.65     â”‚ 0.74        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Logistic Regression  â”‚ 0.78     â”‚ 0.83      â”‚ 0.51   â”‚ 0.63     â”‚ 0.73        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ RidgeClassifier      â”‚ 0.77     â”‚ 0.87      â”‚ 0.45   â”‚ 0.60     â”‚ 0.72        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Passive Aggressive   â”‚ 0.76     â”‚ 0.91      â”‚ 0.41   â”‚ 0.57     â”‚ 0.70        â”‚ 0.05       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ SGDC                 â”‚ 0.76     â”‚ 0.96      â”‚ 0.39   â”‚ 0.55     â”‚ 0.69        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ AdaBoost             â”‚ 0.76     â”‚ 0.99      â”‚ 0.36   â”‚ 0.53     â”‚ 0.68        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">DummyClassifier</span>      â”‚ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.62</span>     â”‚ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>      â”‚ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>   â”‚ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>     â”‚ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.39</span>        â”‚ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                Comparison with Filter Method                                 \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mAlgorithm           \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mAccuracy\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mPrecision\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mRecall\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mF1-score\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mK-Fold mean\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mK-Fold std\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ \u001b[1;32mKNN\u001b[0m                  â”‚ \u001b[1;32m0.79\u001b[0m     â”‚ \u001b[1;32m0.72\u001b[0m      â”‚ \u001b[1;32m0.74\u001b[0m   â”‚ \u001b[1;32m0.73\u001b[0m     â”‚ \u001b[1;32m0.78\u001b[0m        â”‚ \u001b[1;32m0.01\u001b[0m       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Bagging              â”‚ 0.83     â”‚ 0.81      â”‚ 0.73   â”‚ 0.77     â”‚ 0.81        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Stacking             â”‚ 0.84     â”‚ 0.83      â”‚ 0.72   â”‚ 0.77     â”‚ 0.81        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Hard Voting          â”‚ 0.84     â”‚ 0.83      â”‚ 0.71   â”‚ 0.77     â”‚ 0.81        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Soft Voting          â”‚ 0.84     â”‚ 0.84      â”‚ 0.71   â”‚ 0.77     â”‚ 0.81        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ RandomForest         â”‚ 0.82     â”‚ 0.82      â”‚ 0.67   â”‚ 0.74     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ XGBoost              â”‚ 0.82     â”‚ 0.83      â”‚ 0.66   â”‚ 0.74     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ LGBMClassifier       â”‚ 0.82     â”‚ 0.83      â”‚ 0.66   â”‚ 0.74     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ CatBoost             â”‚ 0.81     â”‚ 0.82      â”‚ 0.65   â”‚ 0.72     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ HistGradientBoosting â”‚ 0.81     â”‚ 0.82      â”‚ 0.65   â”‚ 0.72     â”‚ 0.79        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Bagged DT            â”‚ 0.81     â”‚ 0.80      â”‚ 0.65   â”‚ 0.72     â”‚ 0.78        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ DecisionTree         â”‚ 0.80     â”‚ 0.80      â”‚ 0.64   â”‚ 0.71     â”‚ 0.77        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ GradientBoosting     â”‚ 0.80     â”‚ 0.81      â”‚ 0.61   â”‚ 0.70     â”‚ 0.77        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ MLPC                 â”‚ 0.79     â”‚ 0.82      â”‚ 0.58   â”‚ 0.68     â”‚ 0.77        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ ExtraTrees           â”‚ 0.80     â”‚ 0.84      â”‚ 0.58   â”‚ 0.68     â”‚ 0.76        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ SVC                  â”‚ 0.78     â”‚ 0.82      â”‚ 0.54   â”‚ 0.65     â”‚ 0.74        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Logistic Regression  â”‚ 0.78     â”‚ 0.83      â”‚ 0.51   â”‚ 0.63     â”‚ 0.73        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ RidgeClassifier      â”‚ 0.77     â”‚ 0.87      â”‚ 0.45   â”‚ 0.60     â”‚ 0.72        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ Passive Aggressive   â”‚ 0.76     â”‚ 0.91      â”‚ 0.41   â”‚ 0.57     â”‚ 0.70        â”‚ 0.05       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ SGDC                 â”‚ 0.76     â”‚ 0.96      â”‚ 0.39   â”‚ 0.55     â”‚ 0.69        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ AdaBoost             â”‚ 0.76     â”‚ 0.99      â”‚ 0.36   â”‚ 0.53     â”‚ 0.68        â”‚ 0.00       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ \u001b[1;31mDummyClassifier\u001b[0m      â”‚ \u001b[1;31m0.62\u001b[0m     â”‚ \u001b[1;31m0.00\u001b[0m      â”‚ \u001b[1;31m0.00\u001b[0m   â”‚ \u001b[1;31m0.00\u001b[0m     â”‚ \u001b[1;31m0.39\u001b[0m        â”‚ \u001b[1;31m0.00\u001b[0m       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "temp_console = Console(record=True)\n",
    "temp_console.print(table)\n",
    "text = temp_console.export_text()\n",
    "with open('results/feature_selection_compare.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca046fbe",
   "metadata": {},
   "source": [
    "# Another Feature Selections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fb476a",
   "metadata": {},
   "source": [
    "<a href=\"../FS/without_fs.ipynb\" target=\"_blank\" style=\"text-decoration: none;\">\n",
    "    <button style=\"\n",
    "        background-color: #45a049;\n",
    "        color: white; \n",
    "        padding: 12px 24px; \n",
    "        font-size: 16px; \n",
    "        border: none; \n",
    "        border-radius: 8px;\n",
    "        cursor: pointer;\n",
    "        transition: background-color 0.3s;\n",
    "    \" onmouseover=\"this.style.backgroundColor='#45a049'\" onmouseout=\"this.style.backgroundColor='#4CAF50'\">\n",
    "        Without Feature selection \n",
    "    </button>\n",
    "</a>\n",
    "\n",
    "<a href=\"../FS/embedded.ipynb\" target=\"_blank\" style=\"text-decoration: none;\">\n",
    "    <button style=\"\n",
    "        background-color: #45a049;\n",
    "        color: white; \n",
    "        padding: 12px 24px; \n",
    "        font-size: 16px; \n",
    "        border: none; \n",
    "        border-radius: 8px;\n",
    "        cursor: pointer;\n",
    "        transition: background-color 0.3s;\n",
    "    \" onmouseover=\"this.style.backgroundColor='#45a049'\" onmouseout=\"this.style.backgroundColor='#4CAF50'\">\n",
    "        Embedded method\n",
    "    </button>\n",
    "</a>\n",
    "\n",
    "<a href=\"../FS/without_fs.ipynb\" target=\"_blank\" style=\"text-decoration: none;\">\n",
    "    <button style=\"\n",
    "        background-color: #45a049;\n",
    "        color: white; \n",
    "        padding: 12px 24px; \n",
    "        font-size: 16px; \n",
    "        border: none; \n",
    "        border-radius: 8px;\n",
    "        cursor: pointer;\n",
    "        transition: background-color 0.3s;\n",
    "    \" onmouseover=\"this.style.backgroundColor='#45a049'\" onmouseout=\"this.style.backgroundColor='#4CAF50'\">\n",
    "        Wrapper method\n",
    "    </button>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2321d2ca",
   "metadata": {},
   "source": [
    "# Next Step - Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efb6f12",
   "metadata": {},
   "source": [
    "<a href=\"..\\Tuning\\bayesian_optimization.ipynb\" target=\"_blank\" style=\"text-decoration: none;\">\n",
    "    <button style=\"\n",
    "        background-color: #45a049;\n",
    "        color: white; \n",
    "        padding: 12px 24px; \n",
    "        font-size: 16px; \n",
    "        border: none; \n",
    "        border-radius: 8px;\n",
    "        cursor: pointer;\n",
    "        transition: background-color 0.3s;\n",
    "    \" onmouseover=\"this.style.backgroundColor='#45a049'\" onmouseout=\"this.style.backgroundColor='#4CAF50'\">\n",
    "        Bayesian Optimization\n",
    "    </button>\n",
    "</a>\n",
    "\n",
    "<a href=\"../Tuning/manual_search.ipynb\" target=\"_blank\" style=\"text-decoration: none;\">\n",
    "    <button style=\"\n",
    "        background-color: #45a049;\n",
    "        color: white; \n",
    "        padding: 12px 24px; \n",
    "        font-size: 16px; \n",
    "        border: none; \n",
    "        border-radius: 8px;\n",
    "        cursor: pointer;\n",
    "        transition: background-color 0.3s;\n",
    "    \" onmouseover=\"this.style.backgroundColor='#45a049'\" onmouseout=\"this.style.backgroundColor='#4CAF50'\">\n",
    "        Manual Search\n",
    "    </button>\n",
    "</a>\n",
    "\n",
    "<a href=\"../Tuning/optuna.ipynb\" target=\"_blank\" style=\"text-decoration: none;\">\n",
    "    <button style=\"\n",
    "        background-color: #45a049;\n",
    "        color: white; \n",
    "        padding: 12px 24px; \n",
    "        font-size: 16px; \n",
    "        border: none; \n",
    "        border-radius: 8px;\n",
    "        cursor: pointer;\n",
    "        transition: background-color 0.3s;\n",
    "    \" onmouseover=\"this.style.backgroundColor='#45a049'\" onmouseout=\"this.style.backgroundColor='#4CAF50'\">\n",
    "        optuna\n",
    "    </button>\n",
    "</a>\n",
    "\n",
    "<a href=\"../Tuning/random_search.ipynb\" target=\"_blank\" style=\"text-decoration: none;\">\n",
    "    <button style=\"\n",
    "        background-color: #45a049;\n",
    "        color: white; \n",
    "        padding: 12px 24px; \n",
    "        font-size: 16px; \n",
    "        border: none; \n",
    "        border-radius: 8px;\n",
    "        cursor: pointer;\n",
    "        transition: background-color 0.3s;\n",
    "    \" onmouseover=\"this.style.backgroundColor='#45a049'\" onmouseout=\"this.style.backgroundColor='#4CAF50'\">\n",
    "        Random Search\n",
    "    </button>\n",
    "</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
