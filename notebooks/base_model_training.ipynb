{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d69008c",
   "metadata": {},
   "source": [
    "## üîπ Base Model Training ‚Äî Algorithm Families Overview\n",
    "\n",
    "#### üß™Ushbu loyihada base model training bosqichida **classification** uchun **jami 25 ta algoritm** turli model oilalaridan foydalanilgan.\n",
    "\n",
    "Quyida loyihada qo‚Äòllanilgan **asosiy algoritm oilalari** keltirilgan:\n",
    "\n",
    "- üìè **Linear Models**\n",
    "- üå≥ **Tree-Based Models**\n",
    "- üß† **Ensemble Models**\n",
    "- üë• **Neighbors-Based Models**\n",
    "- üìê **Support Vector Machine (SVM) Models**\n",
    "- üåÄ **Kernel-Based Models**\n",
    "- üß¨ **Neural Network Models**\n",
    "- üéØ **Naive & Simple Baseline Models**\n",
    "\n",
    "\n",
    "‚ú® Ushbu model oilalari klassik **baseline** yondashuvlardan tortib,  \n",
    "zamonaviy **ensemble** va **kernel-based** modellargacha bo‚Äòlgan  \n",
    "keng qamrovli yechimlarni o‚Äòz ichiga oladi.\n",
    "\n",
    "üîç Barcha modellar o‚Äòzaro solishtirish, barqarorlikni baholash  \n",
    "va **eng optimal modelni aniqlash** maqsadida birgalikda sinovdan o‚Äòtkazilgan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cebb0060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c357bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\User\\Desktop\\ML_Lesson\\Projects\\hotelBooking_cancelling_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e9211f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/raw/hotel_bookings_updated_2024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d2e657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119390 entries, 0 to 119389\n",
      "Data columns (total 33 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   hotel                           119390 non-null  object \n",
      " 1   is_canceled                     119390 non-null  int64  \n",
      " 2   lead_time                       119390 non-null  int64  \n",
      " 3   arrival_date_year               119390 non-null  int64  \n",
      " 4   arrival_date_month              119390 non-null  object \n",
      " 5   arrival_date_week_number        119390 non-null  int64  \n",
      " 6   arrival_date_day_of_month       119390 non-null  int64  \n",
      " 7   stays_in_weekend_nights         119390 non-null  int64  \n",
      " 8   stays_in_week_nights            119390 non-null  int64  \n",
      " 9   adults                          119390 non-null  int64  \n",
      " 10  children                        119386 non-null  float64\n",
      " 11  babies                          119390 non-null  int64  \n",
      " 12  meal                            119390 non-null  object \n",
      " 13  country                         118902 non-null  object \n",
      " 14  market_segment                  119390 non-null  object \n",
      " 15  distribution_channel            119390 non-null  object \n",
      " 16  is_repeated_guest               119390 non-null  int64  \n",
      " 17  previous_cancellations          119390 non-null  int64  \n",
      " 18  previous_bookings_not_canceled  119390 non-null  int64  \n",
      " 19  reserved_room_type              119390 non-null  object \n",
      " 20  assigned_room_type              119390 non-null  object \n",
      " 21  booking_changes                 119390 non-null  int64  \n",
      " 22  deposit_type                    119390 non-null  object \n",
      " 23  agent                           103050 non-null  float64\n",
      " 24  company                         6797 non-null    float64\n",
      " 25  days_in_waiting_list            119390 non-null  int64  \n",
      " 26  customer_type                   119390 non-null  object \n",
      " 27  adr                             119390 non-null  float64\n",
      " 28  required_car_parking_spaces     119390 non-null  int64  \n",
      " 29  total_of_special_requests       119390 non-null  int64  \n",
      " 30  reservation_status              119390 non-null  object \n",
      " 31  reservation_status_date         119390 non-null  object \n",
      " 32  city                            119390 non-null  object \n",
      "dtypes: float64(4), int64(16), object(13)\n",
      "memory usage: 30.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56701b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_cols = [\n",
    "    'reservation_status',\n",
    "    'reservation_status_date',\n",
    "    'assigned_room_type',\n",
    "    'booking_changes'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=leak_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfeae336",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'train_preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtrain_preprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Preprocessing\n\u001b[32m      3\u001b[39m preprocessing = Preprocessing(df, target=\u001b[33m'\u001b[39m\u001b[33mis_canceled\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m df = preprocessing.fillMissingValues().encode().scale().get_dataset()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'train_preprocessing'"
     ]
    }
   ],
   "source": [
    "from train_preprocessing import Preprocessing\n",
    "\n",
    "preprocessing = Preprocessing(df, target='is_canceled')\n",
    "df = preprocessing.fillMissingValues().encode().scale().get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdddce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(frac=0.4, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33355c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119390 entries, 0 to 119389\n",
      "Data columns (total 29 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   hotel                           119390 non-null  float64\n",
      " 1   is_canceled                     119390 non-null  int64  \n",
      " 2   lead_time                       119390 non-null  float64\n",
      " 3   arrival_date_year               119390 non-null  float64\n",
      " 4   arrival_date_month              119390 non-null  float64\n",
      " 5   arrival_date_week_number        119390 non-null  float64\n",
      " 6   arrival_date_day_of_month       119390 non-null  float64\n",
      " 7   stays_in_weekend_nights         119390 non-null  float64\n",
      " 8   stays_in_week_nights            119390 non-null  float64\n",
      " 9   adults                          119390 non-null  float64\n",
      " 10  children                        119390 non-null  float64\n",
      " 11  babies                          119390 non-null  float64\n",
      " 12  meal                            119390 non-null  float64\n",
      " 13  country                         119390 non-null  float64\n",
      " 14  market_segment                  119390 non-null  float64\n",
      " 15  distribution_channel            119390 non-null  float64\n",
      " 16  is_repeated_guest               119390 non-null  float64\n",
      " 17  previous_cancellations          119390 non-null  float64\n",
      " 18  previous_bookings_not_canceled  119390 non-null  float64\n",
      " 19  reserved_room_type              119390 non-null  float64\n",
      " 20  deposit_type                    119390 non-null  float64\n",
      " 21  agent                           119390 non-null  float64\n",
      " 22  company                         119390 non-null  float64\n",
      " 23  days_in_waiting_list            119390 non-null  float64\n",
      " 24  customer_type                   119390 non-null  float64\n",
      " 25  adr                             119390 non-null  float64\n",
      " 26  required_car_parking_spaces     119390 non-null  float64\n",
      " 27  total_of_special_requests       119390 non-null  float64\n",
      " 28  city                            119390 non-null  float64\n",
      "dtypes: float64(28), int64(1)\n",
      "memory usage: 26.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e9f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('is_canceled', axis=1)   \n",
    "y = df['is_canceled'] \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac20153",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c635fb",
   "metadata": {},
   "source": [
    "### üìå 1. Linear Models \n",
    "**Jami: `4ta` algoritm**\n",
    "\n",
    "- **Logistic Regression**\n",
    "- **Ridge Classifier**\n",
    "- **SGD Classifier**\n",
    "- **Passive Aggressive Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed27eb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR MODELS - CLASSIFICATION (4ta)\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression,\n",
    "    RidgeClassifier,\n",
    "    SGDClassifier,\n",
    "    PassiveAggressiveClassifier\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc4cf5",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e8e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score: 0.7804254962727196\n",
      "\n",
      "Precision: 0.8143338954468803\n",
      "Recall: 0.5382900457028202\n",
      "F1-score: 0.6481444198375947\n",
      "\n",
      "K-Fold mean: 0.7430007714523813\n",
      "K-Fold std: 0.001968997891612834\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84     14907\n",
      "           1       0.81      0.54      0.65      8971\n",
      "\n",
      "    accuracy                           0.78     23878\n",
      "   macro avg       0.79      0.73      0.74     23878\n",
      "weighted avg       0.79      0.78      0.77     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "\n",
    "lr_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "lr_precision = precision_score(y_test, y_pred)\n",
    "lr_recall = recall_score(y_test, y_pred)\n",
    "lr_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "lr_scores = cross_val_score(lr, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'Logistic Regression score: {lr_score}')\n",
    "\n",
    "print(f'\\nPrecision: {lr_precision}')\n",
    "print(f'Recall: {lr_recall}')\n",
    "print(f'F1-score: {lr_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", lr_scores.mean())\n",
    "print(\"K-Fold std:\", lr_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f705569c",
   "metadata": {},
   "source": [
    "## RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202741f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier score: 0.7722171036100176\n",
      "\n",
      "Precision: 0.8561920129084308\n",
      "Recall: 0.4731913944933675\n",
      "F1-score: 0.6095197070859358\n",
      "\n",
      "K-Fold mean: 0.7225008057692177\n",
      "K-Fold std: 0.0023445300855688173\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84     14907\n",
      "           1       0.86      0.47      0.61      8971\n",
      "\n",
      "    accuracy                           0.77     23878\n",
      "   macro avg       0.80      0.71      0.72     23878\n",
      "weighted avg       0.79      0.77      0.75     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ridge = RidgeClassifier()\n",
    "\n",
    "ridge.fit(x_train, y_train)\n",
    "y_pred = ridge.predict(x_test)\n",
    "\n",
    "ridge_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "ridge_precision = precision_score(y_test, y_pred)\n",
    "ridge_recall = recall_score(y_test, y_pred)\n",
    "ridge_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "ridge_scores = cross_val_score(ridge, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'RidgeClassifier score: {ridge_score}')\n",
    "\n",
    "print(f'\\nPrecision: {ridge_precision}')\n",
    "print(f'Recall: {ridge_recall}')\n",
    "print(f'F1-score: {ridge_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", ridge_scores.mean())\n",
    "print(\"K-Fold std:\", ridge_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3260cc52",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97002795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier score: 0.7486389144819499\n",
      "\n",
      "Precision: 0.985289310232102\n",
      "Recall: 0.3359714636049493\n",
      "F1-score: 0.5010806317539485\n",
      "\n",
      "K-Fold mean: 0.6643971286279052\n",
      "K-Fold std: 0.0019021869343241128\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83     14907\n",
      "           1       0.99      0.34      0.50      8971\n",
      "\n",
      "    accuracy                           0.75     23878\n",
      "   macro avg       0.85      0.67      0.67     23878\n",
      "weighted avg       0.82      0.75      0.71     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgdc = SGDClassifier()\n",
    "\n",
    "sgdc.fit(x_train, y_train)\n",
    "y_pred = sgdc.predict(x_test)\n",
    "\n",
    "sgdc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "sgdc_precision = precision_score(y_test, y_pred)\n",
    "sgdc_recall = recall_score(y_test, y_pred)\n",
    "sgdc_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "sgdc_scores = cross_val_score(sgdc, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'SGDClassifier score: {sgdc_score}')\n",
    "\n",
    "print(f'\\nPrecision: {sgdc_precision}')\n",
    "print(f'Recall: {sgdc_recall}')\n",
    "print(f'F1-score: {sgdc_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", sgdc_scores.mean())\n",
    "print(\"K-Fold std:\", sgdc_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e030c02",
   "metadata": {},
   "source": [
    "## PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d83b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier score: 0.7737247675684731\n",
      "\n",
      "Precision: 0.899641577060932\n",
      "Recall: 0.44766469735815406\n",
      "F1-score: 0.59784145887607\n",
      "\n",
      "K-Fold mean: 0.6856275295746914\n",
      "K-Fold std: 0.019650899702376417\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84     14907\n",
      "           1       0.90      0.45      0.60      8971\n",
      "\n",
      "    accuracy                           0.77     23878\n",
      "   macro avg       0.82      0.71      0.72     23878\n",
      "weighted avg       0.80      0.77      0.75     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pac = PassiveAggressiveClassifier()\n",
    "\n",
    "pac.fit(x_train, y_train)\n",
    "y_pred = pac.predict(x_test)\n",
    "\n",
    "pac_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "pac_precision = precision_score(y_test, y_pred)\n",
    "pac_recall = recall_score(y_test, y_pred)\n",
    "pac_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "pac_scores = cross_val_score(pac, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'SGDClassifier score: {pac_score}')\n",
    "\n",
    "print(f'\\nPrecision: {pac_precision}')\n",
    "print(f'Recall: {pac_recall}')\n",
    "print(f'F1-score: {pac_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", pac_scores.mean())\n",
    "print(\"K-Fold std:\", pac_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd565bc",
   "metadata": {},
   "source": [
    "## üå≤ 2. Tree-Based Models\n",
    "\n",
    "**Jami: `1ta` algoritm**\n",
    "\n",
    "- **Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree MODELS (1ta)\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c1054",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79776edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree score: 0.8354971103107462\n",
      "\n",
      "Precision: 0.7885341572262272\n",
      "Recall: 0.7681417902129083\n",
      "F1-score: 0.7782044042913608\n",
      "\n",
      "K-Fold mean: 0.8197420480560437\n",
      "K-Fold std: 0.0018526557978490513\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87     14907\n",
      "           1       0.79      0.77      0.78      8971\n",
      "\n",
      "    accuracy                           0.84     23878\n",
      "   macro avg       0.83      0.82      0.82     23878\n",
      "weighted avg       0.83      0.84      0.84     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=10, min_samples_split=5,random_state=42)\n",
    "\n",
    "dt.fit(x_train, y_train)\n",
    "y_pred = dt.predict(x_test)\n",
    "\n",
    "dt_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "dt_precision = precision_score(y_test, y_pred)\n",
    "dt_recall = recall_score(y_test, y_pred)\n",
    "dt_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "dt_scores = cross_val_score(dt, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'DecisionTree score: {dt_score}')\n",
    "\n",
    "print(f'\\nPrecision: {dt_precision}')\n",
    "print(f'Recall: {dt_recall}')\n",
    "print(f'F1-score: {dt_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", dt_scores.mean())\n",
    "print(\"K-Fold std:\", dt_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a272f392",
   "metadata": {},
   "source": [
    "## üß† 3. Ensemble Models\n",
    "\n",
    "**Jami: `12ta` algoritm**\n",
    "\n",
    "### üì¶ Bagging Family (4ta)\n",
    "- **Random Forest**\n",
    "- **Bagging Classifier**\n",
    "- **Extra Trees**\n",
    "- **Bagged Decision Tree**\n",
    "\n",
    "### üöÄ Boosting Family (6ta)\n",
    "- **Gradient Boosting**\n",
    "- **Hist Gradient Boosting**\n",
    "- **AdaBoost**\n",
    "- **CatBoost**\n",
    "- **XGBoost**\n",
    "- **LightGBM**\n",
    "\n",
    "### üß© Meta-Ensemble Methods\n",
    "- **Stacking**\n",
    "- **Voting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974abfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging MODELS (3ta)\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    BaggingClassifier,\n",
    "    ExtraTreesClassifier\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12418cb7",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304bc3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest score: 0.8612949158220956\n",
      "\n",
      "Precision: 0.8768144892795312\n",
      "Recall: 0.7339204102106789\n",
      "F1-score: 0.7990291262135922\n",
      "\n",
      "K-Fold mean: 0.8444919547484004\n",
      "K-Fold std: 0.0008185887545593961\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89     14907\n",
      "           1       0.88      0.73      0.80      8971\n",
      "\n",
      "    accuracy                           0.86     23878\n",
      "   macro avg       0.87      0.84      0.85     23878\n",
      "weighted avg       0.86      0.86      0.86     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=300, max_depth=15, n_jobs=-1, random_state=42)\n",
    "\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "\n",
    "rf_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "rf_precision = precision_score(y_test, y_pred)\n",
    "rf_recall = recall_score(y_test, y_pred)\n",
    "rf_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "rf_scores = cross_val_score(rf, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'RandomForest score: {rf_score}')\n",
    "\n",
    "print(f'\\nPrecision: {rf_precision}')\n",
    "print(f'Recall: {rf_recall}')\n",
    "print(f'F1-score: {rf_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", rf_scores.mean())\n",
    "print(\"K-Fold std:\", rf_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ec21a0",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faff798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging score: 0.87038277912723\n",
      "\n",
      "Precision: 0.8528705260629353\n",
      "Recall: 0.7915505517779512\n",
      "F1-score: 0.8210672370931376\n",
      "\n",
      "K-Fold mean: 0.857398741399442\n",
      "K-Fold std: 0.0018616642956586981\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90     14907\n",
      "           1       0.85      0.79      0.82      8971\n",
      "\n",
      "    accuracy                           0.87     23878\n",
      "   macro avg       0.87      0.85      0.86     23878\n",
      "weighted avg       0.87      0.87      0.87     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bag = BaggingClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "bag.fit(x_train, y_train)\n",
    "y_pred = bag.predict(x_test)\n",
    "\n",
    "bag_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "bag_precision = precision_score(y_test, y_pred)\n",
    "bag_recall = recall_score(y_test, y_pred)\n",
    "bag_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "bag_scores = cross_val_score(bag, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'Bagging score: {bag_score}')\n",
    "\n",
    "print(f'\\nPrecision: {bag_precision}')\n",
    "print(f'Recall: {bag_recall}')\n",
    "print(f'F1-score: {bag_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", bag_scores.mean())\n",
    "print(\"K-Fold std:\", bag_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e567fab3",
   "metadata": {},
   "source": [
    "## Bagged DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a5c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged DT score: 0.8411089706005528\n",
      "\n",
      "Precision: 0.8171792672466609\n",
      "Recall: 0.7433953851298629\n",
      "F1-score: 0.7785430772822788\n",
      "\n",
      "K-Fold mean: 0.822351007707847\n",
      "K-Fold std: 0.001146249583856674\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88     14907\n",
      "           1       0.82      0.74      0.78      8971\n",
      "\n",
      "    accuracy                           0.84     23878\n",
      "   macro avg       0.84      0.82      0.83     23878\n",
      "weighted avg       0.84      0.84      0.84     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bag_dt = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=10),\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "bag_dt.fit(x_train, y_train)\n",
    "y_pred = bag_dt.predict(x_test)\n",
    "\n",
    "bag_dt_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "bag_dt_precision = precision_score(y_test, y_pred)\n",
    "bag_dt_recall = recall_score(y_test, y_pred)\n",
    "bag_dt_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "bag_dt_scores = cross_val_score(bag_dt, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'Bagged DT score: {bag_dt_score}')\n",
    "\n",
    "print(f'\\nPrecision: {bag_dt_precision}')\n",
    "print(f'Recall: {bag_dt_recall}')\n",
    "print(f'F1-score: {bag_dt_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", bag_dt_scores.mean())\n",
    "print(\"K-Fold std:\", bag_dt_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8c231e",
   "metadata": {},
   "source": [
    "## ExtraTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c0af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees score: 0.8175307814724851\n",
      "\n",
      "Precision: 0.9256457564575645\n",
      "Recall: 0.559246460818192\n",
      "F1-score: 0.6972413313876729\n",
      "\n",
      "K-Fold mean: 0.7837956925761072\n",
      "K-Fold std: 0.004180519733277109\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87     14907\n",
      "           1       0.93      0.56      0.70      8971\n",
      "\n",
      "    accuracy                           0.82     23878\n",
      "   macro avg       0.86      0.77      0.78     23878\n",
      "weighted avg       0.84      0.82      0.80     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=300, max_depth=15, n_jobs=-1, random_state=42)\n",
    "\n",
    "et.fit(x_train, y_train)\n",
    "y_pred = et.predict(x_test)\n",
    "\n",
    "et_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "et_precision = precision_score(y_test, y_pred)\n",
    "et_recall = recall_score(y_test, y_pred)\n",
    "et_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "et_scores = cross_val_score(et, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'ExtraTrees score: {et_score}')\n",
    "\n",
    "print(f'\\nPrecision: {et_precision}')\n",
    "print(f'Recall: {et_recall}')\n",
    "print(f'F1-score: {et_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", et_scores.mean())\n",
    "print(\"K-Fold std:\", et_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044985d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting MODELS (6ta)\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    AdaBoostClassifier\n",
    ")\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db024eba",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95feb181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting score: 0.8449200100510931\n",
      "\n",
      "Precision: 0.8445839874411303\n",
      "Recall: 0.7196522126853193\n",
      "F1-score: 0.7771291002106531\n",
      "\n",
      "K-Fold mean: 0.8269973537984315\n",
      "K-Fold std: 0.0015486814324016098\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88     14907\n",
      "           1       0.84      0.72      0.78      8971\n",
      "\n",
      "    accuracy                           0.84     23878\n",
      "   macro avg       0.84      0.82      0.83     23878\n",
      "weighted avg       0.84      0.84      0.84     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=300, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "\n",
    "gb.fit(x_train, y_train)\n",
    "y_pred = gb.predict(x_test)\n",
    "\n",
    "gb_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "gb_precision = precision_score(y_test, y_pred)\n",
    "gb_recall = recall_score(y_test, y_pred)\n",
    "gb_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "gb_scores = cross_val_score(gb, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'GradientBoosting score: {gb_score}')\n",
    "\n",
    "print(f'\\nPrecision: {gb_precision}')\n",
    "print(f'Recall: {gb_recall}')\n",
    "print(f'F1-score: {gb_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", gb_scores.mean())\n",
    "print(\"K-Fold std:\", gb_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c411f5",
   "metadata": {},
   "source": [
    "## Hist Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a089c2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoosting score: 0.8649803166094313\n",
      "\n",
      "Precision: 0.8540101022545276\n",
      "Recall: 0.77271207223275\n",
      "F1-score: 0.8113295880149812\n",
      "\n",
      "K-Fold mean: 0.849925729458608\n",
      "K-Fold std: 0.0022813782868536673\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89     14907\n",
      "           1       0.85      0.77      0.81      8971\n",
      "\n",
      "    accuracy                           0.86     23878\n",
      "   macro avg       0.86      0.85      0.85     23878\n",
      "weighted avg       0.86      0.86      0.86     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hgb = HistGradientBoostingClassifier(max_iter=300, learning_rate=0.05, max_depth=7, random_state=42)\n",
    "\n",
    "hgb.fit(x_train, y_train)\n",
    "y_pred = hgb.predict(x_test)\n",
    "\n",
    "hgb_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "hgb_precision = precision_score(y_test, y_pred)\n",
    "hgb_recall = recall_score(y_test, y_pred)\n",
    "hgb_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "hgb_scores = cross_val_score(hgb, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'HistGradientBoosting score: {hgb_score}')\n",
    "\n",
    "print(f'\\nPrecision: {hgb_precision}')\n",
    "print(f'Recall: {hgb_recall}')\n",
    "print(f'F1-score: {hgb_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", hgb_scores.mean())\n",
    "print(\"K-Fold std:\", hgb_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1086c21b",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bbfa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost score: 0.8652734734902421\n",
      "\n",
      "Precision: 0.8593554833874594\n",
      "Recall: 0.7669156169880726\n",
      "F1-score: 0.8105083348059139\n",
      "\n",
      "K-Fold mean: 0.8507783026441524\n",
      "K-Fold std: 0.0007762568346698412\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90     14907\n",
      "           1       0.86      0.77      0.81      8971\n",
      "\n",
      "    accuracy                           0.87     23878\n",
      "   macro avg       0.86      0.85      0.85     23878\n",
      "weighted avg       0.86      0.87      0.86     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(x_train, y_train)\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "xgb_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "xgb_precision = precision_score(y_test, y_pred)\n",
    "xgb_recall = recall_score(y_test, y_pred)\n",
    "xgb_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "xgb_scores = cross_val_score(xgb, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'XGBoost score: {xgb_score}')\n",
    "\n",
    "print(f'\\nPrecision: {xgb_precision}')\n",
    "print(f'Recall: {xgb_recall}')\n",
    "print(f'F1-score: {xgb_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", xgb_scores.mean())\n",
    "print(\"K-Fold std:\", xgb_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b29f3cf",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a118f6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost score: 0.7638830722841109\n",
      "\n",
      "Precision: 0.987423223164668\n",
      "Recall: 0.3763237097313566\n",
      "F1-score: 0.5449556093623891\n",
      "\n",
      "K-Fold mean: 0.6768809253456395\n",
      "K-Fold std: 0.010786857939821424\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84     14907\n",
      "           1       0.99      0.38      0.54      8971\n",
      "\n",
      "    accuracy                           0.76     23878\n",
      "   macro avg       0.86      0.69      0.69     23878\n",
      "weighted avg       0.82      0.76      0.73     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostClassifier(n_estimators=300, learning_rate=0.05, random_state=42)\n",
    "\n",
    "ab.fit(x_train, y_train)\n",
    "y_pred = ab.predict(x_test)\n",
    "\n",
    "ab_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "ab_precision = precision_score(y_test, y_pred)\n",
    "ab_recall = recall_score(y_test, y_pred)\n",
    "ab_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "ab_scores = cross_val_score(ab, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'AdaBoost score: {ab_score}')\n",
    "\n",
    "print(f'\\nPrecision: {ab_precision}')\n",
    "print(f'Recall: {ab_recall}')\n",
    "print(f'F1-score: {ab_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", ab_scores.mean())\n",
    "print(\"K-Fold std:\", ab_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edac36a",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31277d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 35253, number of negative: 60259\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1418\n",
      "[LightGBM] [Info] Number of data points in the train set: 95512, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369095 -> initscore=-0.536101\n",
      "[LightGBM] [Info] Start training from score -0.536101\n",
      "[LightGBM] [Info] Number of positive: 29434, number of negative: 50159\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1409\n",
      "[LightGBM] [Info] Number of data points in the train set: 79593, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369806 -> initscore=-0.533047\n",
      "[LightGBM] [Info] Start training from score -0.533047\n",
      "[LightGBM] [Info] Number of positive: 29468, number of negative: 50125\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1412\n",
      "[LightGBM] [Info] Number of data points in the train set: 79593, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370234 -> initscore=-0.531215\n",
      "[LightGBM] [Info] Start training from score -0.531215\n",
      "[LightGBM] [Info] Number of positive: 29546, number of negative: 50048\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1405\n",
      "[LightGBM] [Info] Number of data points in the train set: 79594, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.371209 -> initscore=-0.527034\n",
      "[LightGBM] [Info] Start training from score -0.527034\n",
      "\n",
      "LightGBM score: 0.8702571404640255\n",
      "\n",
      "Precision: 0.8579787882482018\n",
      "Recall: 0.7845279233084383\n",
      "F1-score: 0.8196110399441016\n",
      "\n",
      "K-Fold mean: 0.8551534038970777\n",
      "K-Fold std: 0.0021544682335736076\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90     14907\n",
      "           1       0.86      0.78      0.82      8971\n",
      "\n",
      "    accuracy                           0.87     23878\n",
      "   macro avg       0.87      0.85      0.86     23878\n",
      "weighted avg       0.87      0.87      0.87     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=31, subsample=0.8, colsample_bytree=0.8, random_state=42)\n",
    "\n",
    "lgbm.fit(x_train, y_train)\n",
    "y_pred = lgbm.predict(x_test)\n",
    "\n",
    "lgbm_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "lgbm_precision = precision_score(y_test, y_pred)\n",
    "lgbm_recall = recall_score(y_test, y_pred)\n",
    "lgbm_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'\\nLightGBM score: {lgbm_score}')\n",
    "\n",
    "print(f'\\nPrecision: {lgbm_precision}')\n",
    "print(f'Recall: {lgbm_recall}')\n",
    "print(f'F1-score: {lgbm_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", lgbm_scores.mean())\n",
    "print(\"K-Fold std:\", lgbm_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ffe45",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4685bfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost score: 0.868288801407153\n",
      "\n",
      "Precision: 0.8580383480825958\n",
      "Recall: 0.7781741165979267\n",
      "F1-score: 0.8161571286607822\n",
      "\n",
      "K-Fold mean: 0.8527816939496814\n",
      "K-Fold std: 0.0014102605038166936\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90     14907\n",
      "           1       0.86      0.78      0.82      8971\n",
      "\n",
      "    accuracy                           0.87     23878\n",
      "   macro avg       0.87      0.85      0.86     23878\n",
      "weighted avg       0.87      0.87      0.87     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(iterations=500, depth=8,learning_rate=0.05, verbose=False, random_state=42)\n",
    "\n",
    "cat.fit(x_train, y_train)\n",
    "y_pred = cat.predict(x_test)\n",
    "\n",
    "cat_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "cat_precision = precision_score(y_test, y_pred)\n",
    "cat_recall = recall_score(y_test, y_pred)\n",
    "cat_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "cat_scores = cross_val_score(cat, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'CatBoost score: {cat_score}')\n",
    "\n",
    "print(f'\\nPrecision: {cat_precision}')\n",
    "print(f'Recall: {cat_recall}')\n",
    "print(f'F1-score: {cat_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", cat_scores.mean())\n",
    "print(\"K-Fold std:\", cat_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24812fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking & Voting MODELS\n",
    "from sklearn.ensemble import (\n",
    "    StackingClassifier,\n",
    "    VotingClassifier\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f49b8c",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9308e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking score: 0.8719742021944886\n",
      "\n",
      "Precision: 0.8597323600973236\n",
      "Recall: 0.7877605618102775\n",
      "F1-score: 0.822174393578035\n",
      "\n",
      "K-Fold mean: 0.846977100538339\n",
      "K-Fold std: 0.001370871323047349\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90     14907\n",
      "           1       0.86      0.79      0.82      8971\n",
      "\n",
      "    accuracy                           0.87     23878\n",
      "   macro avg       0.87      0.86      0.86     23878\n",
      "weighted avg       0.87      0.87      0.87     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base1 = RandomForestClassifier(random_state=42)\n",
    "base2 = ExtraTreesClassifier(random_state=42)\n",
    "base3 = LogisticRegression()\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', base1),\n",
    "        ('et', base2),\n",
    "        ('lr', base3)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "stacking.fit(x_train, y_train)\n",
    "y_pred = stacking.predict(x_test)\n",
    "\n",
    "stacking_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "stacking_precision = precision_score(y_test, y_pred)\n",
    "stacking_recall = recall_score(y_test, y_pred)\n",
    "stacking_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "stacking_scores = cross_val_score(stacking, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'Stacking score: {stacking_score}')\n",
    "\n",
    "print(f'\\nPrecision: {stacking_precision}')\n",
    "print(f'Recall: {stacking_recall}')\n",
    "print(f'F1-score: {stacking_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", stacking_scores.mean())\n",
    "print(\"K-Fold std:\", stacking_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7cad15",
   "metadata": {},
   "source": [
    "## Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f94a9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting score: 0.8684563196247592\n",
      "\n",
      "Precision: 0.8830486202365309\n",
      "Recall: 0.7490803700813733\n",
      "F1-score: 0.8105663108377058\n",
      "\n",
      "K-Fold mean: 0.8495472558679857\n",
      "K-Fold std: 0.0010861818273958752\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     14907\n",
      "           1       0.88      0.75      0.81      8971\n",
      "\n",
      "    accuracy                           0.87     23878\n",
      "   macro avg       0.87      0.84      0.85     23878\n",
      "weighted avg       0.87      0.87      0.87     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestClassifier(random_state=42)\n",
    "model2 = ExtraTreesClassifier(random_state=42)\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "hard_voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', model1),\n",
    "        ('et', model2),\n",
    "        ('lr', model3)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "hard_voting.fit(x_train, y_train)\n",
    "y_pred = hard_voting.predict(x_test)\n",
    "\n",
    "hard_voting_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "hard_voting_precision = precision_score(y_test, y_pred)\n",
    "hard_voting_recall = recall_score(y_test, y_pred)\n",
    "hard_voting_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "hard_voting_scores = cross_val_score(hard_voting, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'Hard Voting score: {hard_voting_score}')\n",
    "\n",
    "print(f'\\nPrecision: {hard_voting_precision}')\n",
    "print(f'Recall: {hard_voting_recall}')\n",
    "print(f'F1-score: {hard_voting_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", hard_voting_scores.mean())\n",
    "print(\"K-Fold std:\", hard_voting_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66adb6df",
   "metadata": {},
   "source": [
    "## Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e22596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Voting score: 0.8639752073037943\n",
      "\n",
      "Precision: 0.8881052488810525\n",
      "Recall: 0.7299074796566715\n",
      "F1-score: 0.8012726382770435\n",
      "\n",
      "K-Fold mean: 0.8449554948662451\n",
      "K-Fold std: 0.001066160040219426\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.90     14907\n",
      "           1       0.89      0.73      0.80      8971\n",
      "\n",
      "    accuracy                           0.86     23878\n",
      "   macro avg       0.87      0.84      0.85     23878\n",
      "weighted avg       0.87      0.86      0.86     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestClassifier(random_state=42)\n",
    "model2 = ExtraTreesClassifier(random_state=42)\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "soft_voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', model1),\n",
    "        ('et', model2),\n",
    "        ('lr', model3)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "soft_voting.fit(x_train, y_train)\n",
    "y_pred = soft_voting.predict(x_test)\n",
    "\n",
    "soft_voting_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "soft_voting_precision = precision_score(y_test, y_pred)\n",
    "soft_voting_recall = recall_score(y_test, y_pred)\n",
    "soft_voting_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "soft_voting_scores = cross_val_score(soft_voting, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'Soft Voting score: {soft_voting_score}')\n",
    "\n",
    "print(f'\\nPrecision: {soft_voting_precision}')\n",
    "print(f'Recall: {soft_voting_recall}')\n",
    "print(f'F1-score: {soft_voting_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", soft_voting_scores.mean())\n",
    "print(\"K-Fold std:\", soft_voting_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48167e01",
   "metadata": {},
   "source": [
    "## üë• 4. Neighbors-Based Models\n",
    "\n",
    "**Jami: `1ta` algoritm**\n",
    "\n",
    "- **K-Nearest Neighbors (KNN) Classifier**\n",
    "- **Radius Neighbors Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338e60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keighbors MODELS (1ta)\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fb8cd0",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a43d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score: 0.7398442080576263\n",
      "\n",
      "Precision: 0.6507815061755383\n",
      "Recall: 0.6636941255155501\n",
      "F1-score: 0.6571743929359823\n",
      "\n",
      "K-Fold mean: 0.7175767328168599\n",
      "K-Fold std: 0.0011166702224954274\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79     14907\n",
      "           1       0.65      0.66      0.66      8971\n",
      "\n",
      "    accuracy                           0.74     23878\n",
      "   macro avg       0.72      0.72      0.72     23878\n",
      "weighted avg       0.74      0.74      0.74     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "\n",
    "knn_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "knn_precision = precision_score(y_test, y_pred)\n",
    "knn_recall = recall_score(y_test, y_pred)\n",
    "knn_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "knn_scores = cross_val_score(knn, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'KNN score: {knn_score}')\n",
    "\n",
    "print(f'\\nPrecision: {knn_precision}')\n",
    "print(f'Recall: {knn_recall}')\n",
    "print(f'F1-score: {knn_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", knn_scores.mean())\n",
    "print(\"K-Fold std:\", knn_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4bdb2",
   "metadata": {},
   "source": [
    "## üìê 5. Support Vector Machine (SVM) Models\n",
    "\n",
    "**Jami: `1ta` algoritm**\n",
    "\n",
    "- **Support Vector Classifier (SVC)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc799c2",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd42a1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC score: 0.8222212915654578\n",
      "\n",
      "Precision: 0.8290169869117238\n",
      "Recall: 0.6636941255155501\n",
      "F1-score: 0.7372005200272396\n",
      "\n",
      "K-Fold mean: 0.799829837926891\n",
      "K-Fold std: 0.0012364581266971796\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87     14907\n",
      "           1       0.83      0.66      0.74      8971\n",
      "\n",
      "    accuracy                           0.82     23878\n",
      "   macro avg       0.82      0.79      0.80     23878\n",
      "weighted avg       0.82      0.82      0.82     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svr = SVC(kernel='rbf', C=20.0)\n",
    "\n",
    "svr.fit(x_train, y_train)\n",
    "y_pred = svr.predict(x_test)\n",
    "\n",
    "svr_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "svr_precision = precision_score(y_test, y_pred)\n",
    "svr_recall = recall_score(y_test, y_pred)\n",
    "svr_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "svr_scores = cross_val_score(svr, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'SVC score: {svr_score}')\n",
    "\n",
    "print(f'\\nPrecision: {svr_precision}')\n",
    "print(f'Recall: {svr_recall}')\n",
    "print(f'F1-score: {svr_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", svr_scores.mean())\n",
    "print(\"K-Fold std:\", svr_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cd371b",
   "metadata": {},
   "source": [
    "## üß¨ 6. Neural Network Models\n",
    "\n",
    "**Jami: `1ta` algoritm**\n",
    "\n",
    "- **Multi-Layer Perceptron (MLP) Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee6706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network MODEL\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d738ebe",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8421986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier score: 0.8386380768908619\n",
      "\n",
      "Precision: 0.8236782190741209\n",
      "Recall: 0.7258945491026642\n",
      "F1-score: 0.7717011317177224\n",
      "\n",
      "K-Fold mean: 0.8190416175578581\n",
      "K-Fold std: 0.0018377222646445372\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88     14907\n",
      "           1       0.82      0.73      0.77      8971\n",
      "\n",
      "    accuracy                           0.84     23878\n",
      "   macro avg       0.83      0.82      0.82     23878\n",
      "weighted avg       0.84      0.84      0.84     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlpc = MLPClassifier(hidden_layer_sizes=(128, 64), activation=\"relu\", max_iter=300, random_state=42)\n",
    "\n",
    "mlpc.fit(x_train, y_train)\n",
    "y_pred = mlpc.predict(x_test)\n",
    "\n",
    "mlpc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "mlpc_precision = precision_score(y_test, y_pred)\n",
    "mlpc_recall = recall_score(y_test, y_pred)\n",
    "mlpc_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "mlpc_scores = cross_val_score(mlpc, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'MLPClassifier score: {mlpc_score}')\n",
    "\n",
    "print(f'\\nPrecision: {mlpc_precision}')\n",
    "print(f'Recall: {mlpc_recall}')\n",
    "print(f'F1-score: {mlpc_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", mlpc_scores.mean())\n",
    "print(\"K-Fold std:\", mlpc_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a1ac2",
   "metadata": {},
   "source": [
    "## üéØ 7. Naive & Simple Baseline Models\n",
    "\n",
    "**Jami: `1ta` algoritm**\n",
    "\n",
    "- **Dummy Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Baseline MODEL\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d7f26b",
   "metadata": {},
   "source": [
    "## DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8a02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier score: 0.6242985174637742\n",
      "\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "\n",
      "K-Fold mean: 0.3863460342179164\n",
      "K-Fold std: 0.00044193153890602284\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77     14907\n",
      "           1       0.00      0.00      0.00      8971\n",
      "\n",
      "    accuracy                           0.62     23878\n",
      "   macro avg       0.31      0.50      0.38     23878\n",
      "weighted avg       0.39      0.62      0.48     23878\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier()\n",
    "\n",
    "dummy.fit(x_train, y_train)\n",
    "y_pred = dummy.predict(x_test)\n",
    "\n",
    "dummy_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "dummy_precision = precision_score(y_test, y_pred)\n",
    "dummy_recall = recall_score(y_test, y_pred)\n",
    "dummy_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "dummy_scores = cross_val_score(dummy, x, y, cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'DummyClassifier score: {dummy_score}')\n",
    "\n",
    "print(f'\\nPrecision: {dummy_precision}')\n",
    "print(f'Recall: {dummy_recall}')\n",
    "print(f'F1-score: {dummy_f1}')\n",
    "\n",
    "print(\"\\nK-Fold mean:\", dummy_scores.mean())\n",
    "print(\"K-Fold std:\", dummy_scores.std()) \n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd52380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                        Base model training Comparison (100% Sampled dataset)                        </span>\n",
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Algorithm            </span>‚îÉ<span style=\"font-weight: bold\"> R2 score </span>‚îÉ<span style=\"font-weight: bold\"> MAE  </span>‚îÉ<span style=\"font-weight: bold\"> K-Fold mean </span>‚îÉ<span style=\"font-weight: bold\"> K-Fold std </span>‚îÉ<span style=\"font-weight: bold\"> Presicion </span>‚îÉ<span style=\"font-weight: bold\"> Recall </span>‚îÉ<span style=\"font-weight: bold\"> f1-score </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Stacking</span>             ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.87</span>     ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.85</span> ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.00</span>        ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.86</span>       ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.79</span>      ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.82</span>   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Bagging              ‚îÇ 0.87     ‚îÇ 0.86 ‚îÇ 0.00        ‚îÇ 0.85       ‚îÇ 0.79      ‚îÇ 0.82   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ LGBMClassifier       ‚îÇ 0.87     ‚îÇ 0.86 ‚îÇ 0.00        ‚îÇ 0.86       ‚îÇ 0.78      ‚îÇ 0.82   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Hard Voting          ‚îÇ 0.87     ‚îÇ 0.85 ‚îÇ 0.00        ‚îÇ 0.88       ‚îÇ 0.75      ‚îÇ 0.81   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ CatBoost             ‚îÇ 0.87     ‚îÇ 0.85 ‚îÇ 0.00        ‚îÇ 0.86       ‚îÇ 0.78      ‚îÇ 0.82   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ XGBoost              ‚îÇ 0.87     ‚îÇ 0.85 ‚îÇ 0.00        ‚îÇ 0.86       ‚îÇ 0.77      ‚îÇ 0.81   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ HistGradientBoosting ‚îÇ 0.86     ‚îÇ 0.85 ‚îÇ 0.00        ‚îÇ 0.85       ‚îÇ 0.77      ‚îÇ 0.81   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Soft Voting          ‚îÇ 0.86     ‚îÇ 0.84 ‚îÇ 0.00        ‚îÇ 0.89       ‚îÇ 0.73      ‚îÇ 0.80   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ RandomForest         ‚îÇ 0.86     ‚îÇ 0.84 ‚îÇ 0.00        ‚îÇ 0.88       ‚îÇ 0.73      ‚îÇ 0.80   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ GradientBoosting     ‚îÇ 0.84     ‚îÇ 0.83 ‚îÇ 0.00        ‚îÇ 0.84       ‚îÇ 0.72      ‚îÇ 0.78   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Bagged DT            ‚îÇ 0.84     ‚îÇ 0.82 ‚îÇ 0.00        ‚îÇ 0.82       ‚îÇ 0.74      ‚îÇ 0.78   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ MLPC                 ‚îÇ 0.84     ‚îÇ 0.82 ‚îÇ 0.00        ‚îÇ 0.82       ‚îÇ 0.73      ‚îÇ 0.77   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ DecisionTree         ‚îÇ 0.84     ‚îÇ 0.82 ‚îÇ 0.00        ‚îÇ 0.79       ‚îÇ 0.77      ‚îÇ 0.78   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ SVC                  ‚îÇ 0.82     ‚îÇ 0.80 ‚îÇ 0.00        ‚îÇ 0.83       ‚îÇ 0.66      ‚îÇ 0.74   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ ExtraTrees           ‚îÇ 0.82     ‚îÇ 0.78 ‚îÇ 0.00        ‚îÇ 0.93       ‚îÇ 0.56      ‚îÇ 0.70   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Logistic Regression  ‚îÇ 0.78     ‚îÇ 0.74 ‚îÇ 0.00        ‚îÇ 0.81       ‚îÇ 0.54      ‚îÇ 0.65   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Passive Aggressive   ‚îÇ 0.77     ‚îÇ 0.69 ‚îÇ 0.02        ‚îÇ 0.90       ‚îÇ 0.45      ‚îÇ 0.60   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ RidgeClassifier      ‚îÇ 0.77     ‚îÇ 0.72 ‚îÇ 0.00        ‚îÇ 0.86       ‚îÇ 0.47      ‚îÇ 0.61   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ AdaBoost             ‚îÇ 0.76     ‚îÇ 0.68 ‚îÇ 0.01        ‚îÇ 0.99       ‚îÇ 0.38      ‚îÇ 0.54   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ SGDC                 ‚îÇ 0.75     ‚îÇ 0.66 ‚îÇ 0.00        ‚îÇ 0.99       ‚îÇ 0.34      ‚îÇ 0.50   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ KNN                  ‚îÇ 0.74     ‚îÇ 0.72 ‚îÇ 0.00        ‚îÇ 0.65       ‚îÇ 0.66      ‚îÇ 0.66   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">DummyClassifier</span>      ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.62</span>     ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.39</span> ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>        ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>       ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>      ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>   ‚îÇ          ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                        Base model training Comparison (100% Sampled dataset)                        \u001b[0m\n",
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mAlgorithm           \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mR2 score\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mMAE \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mK-Fold mean\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mK-Fold std\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mPresicion\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mRecall\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mf1-score\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ \u001b[1;32mStacking\u001b[0m             ‚îÇ \u001b[1;32m0.87\u001b[0m     ‚îÇ \u001b[1;32m0.85\u001b[0m ‚îÇ \u001b[1;32m0.00\u001b[0m        ‚îÇ \u001b[1;32m0.86\u001b[0m       ‚îÇ \u001b[1;32m0.79\u001b[0m      ‚îÇ \u001b[1;32m0.82\u001b[0m   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Bagging              ‚îÇ 0.87     ‚îÇ 0.86 ‚îÇ 0.00        ‚îÇ 0.85       ‚îÇ 0.79      ‚îÇ 0.82   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ LGBMClassifier       ‚îÇ 0.87     ‚îÇ 0.86 ‚îÇ 0.00        ‚îÇ 0.86       ‚îÇ 0.78      ‚îÇ 0.82   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Hard Voting          ‚îÇ 0.87     ‚îÇ 0.85 ‚îÇ 0.00        ‚îÇ 0.88       ‚îÇ 0.75      ‚îÇ 0.81   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ CatBoost             ‚îÇ 0.87     ‚îÇ 0.85 ‚îÇ 0.00        ‚îÇ 0.86       ‚îÇ 0.78      ‚îÇ 0.82   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ XGBoost              ‚îÇ 0.87     ‚îÇ 0.85 ‚îÇ 0.00        ‚îÇ 0.86       ‚îÇ 0.77      ‚îÇ 0.81   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ HistGradientBoosting ‚îÇ 0.86     ‚îÇ 0.85 ‚îÇ 0.00        ‚îÇ 0.85       ‚îÇ 0.77      ‚îÇ 0.81   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Soft Voting          ‚îÇ 0.86     ‚îÇ 0.84 ‚îÇ 0.00        ‚îÇ 0.89       ‚îÇ 0.73      ‚îÇ 0.80   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ RandomForest         ‚îÇ 0.86     ‚îÇ 0.84 ‚îÇ 0.00        ‚îÇ 0.88       ‚îÇ 0.73      ‚îÇ 0.80   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ GradientBoosting     ‚îÇ 0.84     ‚îÇ 0.83 ‚îÇ 0.00        ‚îÇ 0.84       ‚îÇ 0.72      ‚îÇ 0.78   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Bagged DT            ‚îÇ 0.84     ‚îÇ 0.82 ‚îÇ 0.00        ‚îÇ 0.82       ‚îÇ 0.74      ‚îÇ 0.78   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ MLPC                 ‚îÇ 0.84     ‚îÇ 0.82 ‚îÇ 0.00        ‚îÇ 0.82       ‚îÇ 0.73      ‚îÇ 0.77   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ DecisionTree         ‚îÇ 0.84     ‚îÇ 0.82 ‚îÇ 0.00        ‚îÇ 0.79       ‚îÇ 0.77      ‚îÇ 0.78   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ SVC                  ‚îÇ 0.82     ‚îÇ 0.80 ‚îÇ 0.00        ‚îÇ 0.83       ‚îÇ 0.66      ‚îÇ 0.74   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ ExtraTrees           ‚îÇ 0.82     ‚îÇ 0.78 ‚îÇ 0.00        ‚îÇ 0.93       ‚îÇ 0.56      ‚îÇ 0.70   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Logistic Regression  ‚îÇ 0.78     ‚îÇ 0.74 ‚îÇ 0.00        ‚îÇ 0.81       ‚îÇ 0.54      ‚îÇ 0.65   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Passive Aggressive   ‚îÇ 0.77     ‚îÇ 0.69 ‚îÇ 0.02        ‚îÇ 0.90       ‚îÇ 0.45      ‚îÇ 0.60   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ RidgeClassifier      ‚îÇ 0.77     ‚îÇ 0.72 ‚îÇ 0.00        ‚îÇ 0.86       ‚îÇ 0.47      ‚îÇ 0.61   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ AdaBoost             ‚îÇ 0.76     ‚îÇ 0.68 ‚îÇ 0.01        ‚îÇ 0.99       ‚îÇ 0.38      ‚îÇ 0.54   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ SGDC                 ‚îÇ 0.75     ‚îÇ 0.66 ‚îÇ 0.00        ‚îÇ 0.99       ‚îÇ 0.34      ‚îÇ 0.50   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ KNN                  ‚îÇ 0.74     ‚îÇ 0.72 ‚îÇ 0.00        ‚îÇ 0.65       ‚îÇ 0.66      ‚îÇ 0.66   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ \u001b[1;31mDummyClassifier\u001b[0m      ‚îÇ \u001b[1;31m0.62\u001b[0m     ‚îÇ \u001b[1;31m0.39\u001b[0m ‚îÇ \u001b[1;31m0.00\u001b[0m        ‚îÇ \u001b[1;31m0.00\u001b[0m       ‚îÇ \u001b[1;31m0.00\u001b[0m      ‚îÇ \u001b[1;31m0.00\u001b[0m   ‚îÇ          ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "\n",
    "results = [\n",
    "    # Linear Family\n",
    "    ['Logistic Regression', lr_score, lr_precision, lr_recall, lr_f1, lr_scores.mean(), lr_scores.std()],\n",
    "    ['RidgeClassifier', ridge_score, ridge_precision, ridge_recall, ridge_f1, ridge_scores.mean(), ridge_scores.std()],\n",
    "    ['SGDC', sgdc_score, sgdc_precision, sgdc_recall, sgdc_f1, sgdc_scores.mean(), sgdc_scores.std()],\n",
    "    ['Passive Aggressive', pac_score, pac_precision, pac_recall, pac_f1, pac_scores.mean(), pac_scores.std()],\n",
    "\n",
    "    # Tree-Based Family\n",
    "    ['DecisionTree', dt_score, dt_precision, dt_recall, dt_f1, dt_scores.mean(), dt_scores.std()],\n",
    "\n",
    "    # Bagging Family\n",
    "    ['RandomForest', rf_score, rf_precision, rf_recall, rf_f1, rf_scores.mean(), rf_scores.std()],\n",
    "    ['Bagging', bag_score, bag_precision, bag_recall, bag_f1, bag_scores.mean(), bag_scores.std()],\n",
    "    ['Bagged DT', bag_dt_score, bag_dt_precision, bag_dt_recall, bag_dt_f1, bag_dt_scores.mean(), bag_dt_scores.std()],\n",
    "    ['ExtraTrees', et_score, et_precision, et_recall, et_f1, et_scores.mean(), et_scores.std()],\n",
    "\n",
    "    # Boosting Family\n",
    "    ['GradientBoosting', gb_score, gb_precision, gb_recall, gb_f1, gb_scores.mean(), gb_scores.std()],\n",
    "    ['HistGradientBoosting', hgb_score, hgb_precision, hgb_recall, hgb_f1, hgb_scores.mean(), hgb_scores.std()],\n",
    "    ['XGBoost', xgb_score, xgb_precision, xgb_recall, xgb_f1, xgb_scores.mean(), xgb_scores.std()],\n",
    "    ['AdaBoost', ab_score, ab_precision, ab_recall, ab_f1, ab_scores.mean(), ab_scores.std()],\n",
    "    ['LGBMClassifier', lgbm_score, lgbm_precision, lgbm_recall, lgbm_f1, lgbm_scores.mean(), lgbm_scores.std()],\n",
    "    ['CatBoost', cat_score, cat_precision, cat_recall, cat_f1, cat_scores.mean(), cat_scores.std()],\n",
    "\n",
    "    # Stacking & Voting Family\n",
    "    ['Hard Voting', hard_voting_score, hard_voting_precision, hard_voting_recall, hard_voting_f1, hard_voting_scores.mean(), hard_voting_scores.std()],\n",
    "    ['Soft Voting', soft_voting_score, soft_voting_precision, soft_voting_recall, soft_voting_f1, soft_voting_scores.mean(), soft_voting_scores.std()],\n",
    "    ['Stacking', stacking_score, stacking_precision, stacking_recall, stacking_f1, stacking_scores.mean(), stacking_scores.std()],\n",
    "\n",
    "    # Neighbors Family\n",
    "    ['KNN', knn_score, knn_precision, knn_recall, knn_f1, knn_scores.mean(), knn_scores.std()],\n",
    "\n",
    "    # SVM Family\n",
    "    ['SVC', svr_score, svr_precision, svr_recall, svr_f1, svr_scores.mean(), svr_scores.std()],\n",
    "\n",
    "    # Neural Network Family\n",
    "    ['MLPC', mlpc_score, mlpc_precision, mlpc_recall, mlpc_f1, mlpc_scores.mean(), mlpc_scores.std()],\n",
    "\n",
    "    # Naive & Simple Family\n",
    "    ['DummyClassifier', dummy_score, dummy_precision, dummy_recall, dummy_f1, dummy_scores.mean(), dummy_scores.std()],\n",
    "]\n",
    "\n",
    "result_sorted = sorted(results, key=lambda i: i[1], reverse=True)\n",
    "\n",
    "best_model = max(results, key=lambda x: x[1])\n",
    "worst_model = min(results, key=lambda x: x[1])\n",
    "\n",
    "table = Table(title=\"Base model training Comparison\", show_lines=True)\n",
    "table.add_column(\"Algorithm\")\n",
    "table.add_column(\"Accuracy\")\n",
    "table.add_column(\"Precision\")\n",
    "table.add_column(\"Recall\")\n",
    "table.add_column(\"F1-score\")\n",
    "table.add_column(\"K-Fold mean\")\n",
    "table.add_column(\"K-Fold std\")\n",
    "\n",
    "for row in result_sorted:\n",
    "    algo, acc, kmean, kstd, presicion, recall, f1 = row\n",
    "\n",
    "    if row == best_model:\n",
    "        table.add_row(\n",
    "            f\"[bold green]{algo}[/bold green]\",\n",
    "            f\"[bold green]{acc:.2f}[/bold green]\",\n",
    "            f\"[bold green]{presicion:.2f}[/bold green]\",\n",
    "            f\"[bold green]{recall:.2f}[/bold green]\",\n",
    "            f\"[bold green]{f1:.2f}[/bold green]\",\n",
    "            f\"[bold green]{kmean:.2f}[/bold green]\",\n",
    "            f\"[bold green]{kstd:.2f}[/bold green]\",\n",
    "        )\n",
    "    elif row == worst_model:\n",
    "        table.add_row(\n",
    "            f\"[bold red]{algo}[/bold red]\",\n",
    "            f\"[bold red]{acc:.2f}[/bold red]\",\n",
    "            f\"[bold red]{presicion:.2f}[/bold red]\",\n",
    "            f\"[bold red]{recall:.2f}[/bold red]\",\n",
    "            f\"[bold red]{f1:.2f}[/bold red]\",\n",
    "            f\"[bold red]{kmean:.2f}[/bold red]\",\n",
    "            f\"[bold red]{kstd:.2f}[/bold red]\",\n",
    "        )\n",
    "    else:\n",
    "        table.add_row(algo, f\"{acc:.2f}\", f\"{presicion:.2f}\", f\"{recall:.2f}\", f\"{f1:.2f}\", f\"{kmean:.2f}\", f\"{kstd:.2f}\")\n",
    "\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7797b0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                        Base model training Comparison (100% Sampled dataset)                        </span>\n",
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Algorithm            </span>‚îÉ<span style=\"font-weight: bold\"> R2 score </span>‚îÉ<span style=\"font-weight: bold\"> MAE  </span>‚îÉ<span style=\"font-weight: bold\"> K-Fold mean </span>‚îÉ<span style=\"font-weight: bold\"> K-Fold std </span>‚îÉ<span style=\"font-weight: bold\"> Presicion </span>‚îÉ<span style=\"font-weight: bold\"> Recall </span>‚îÉ<span style=\"font-weight: bold\"> f1-score </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Stacking</span>             ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.87</span>     ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.85</span> ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.00</span>        ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.86</span>       ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.79</span>      ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.82</span>   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Bagging              ‚îÇ 0.87     ‚îÇ 0.86 ‚îÇ 0.00        ‚îÇ 0.85       ‚îÇ 0.79      ‚îÇ 0.82   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ LGBMClassifier       ‚îÇ 0.87     ‚îÇ 0.86 ‚îÇ 0.00        ‚îÇ 0.86       ‚îÇ 0.78      ‚îÇ 0.82   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Hard Voting          ‚îÇ 0.87     ‚îÇ 0.85 ‚îÇ 0.00        ‚îÇ 0.88       ‚îÇ 0.75      ‚îÇ 0.81   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ CatBoost             ‚îÇ 0.87     ‚îÇ 0.85 ‚îÇ 0.00        ‚îÇ 0.86       ‚îÇ 0.78      ‚îÇ 0.82   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ XGBoost              ‚îÇ 0.87     ‚îÇ 0.85 ‚îÇ 0.00        ‚îÇ 0.86       ‚îÇ 0.77      ‚îÇ 0.81   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ HistGradientBoosting ‚îÇ 0.86     ‚îÇ 0.85 ‚îÇ 0.00        ‚îÇ 0.85       ‚îÇ 0.77      ‚îÇ 0.81   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Soft Voting          ‚îÇ 0.86     ‚îÇ 0.84 ‚îÇ 0.00        ‚îÇ 0.89       ‚îÇ 0.73      ‚îÇ 0.80   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ RandomForest         ‚îÇ 0.86     ‚îÇ 0.84 ‚îÇ 0.00        ‚îÇ 0.88       ‚îÇ 0.73      ‚îÇ 0.80   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ GradientBoosting     ‚îÇ 0.84     ‚îÇ 0.83 ‚îÇ 0.00        ‚îÇ 0.84       ‚îÇ 0.72      ‚îÇ 0.78   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Bagged DT            ‚îÇ 0.84     ‚îÇ 0.82 ‚îÇ 0.00        ‚îÇ 0.82       ‚îÇ 0.74      ‚îÇ 0.78   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ MLPC                 ‚îÇ 0.84     ‚îÇ 0.82 ‚îÇ 0.00        ‚îÇ 0.82       ‚îÇ 0.73      ‚îÇ 0.77   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ DecisionTree         ‚îÇ 0.84     ‚îÇ 0.82 ‚îÇ 0.00        ‚îÇ 0.79       ‚îÇ 0.77      ‚îÇ 0.78   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ SVC                  ‚îÇ 0.82     ‚îÇ 0.80 ‚îÇ 0.00        ‚îÇ 0.83       ‚îÇ 0.66      ‚îÇ 0.74   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ ExtraTrees           ‚îÇ 0.82     ‚îÇ 0.78 ‚îÇ 0.00        ‚îÇ 0.93       ‚îÇ 0.56      ‚îÇ 0.70   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Logistic Regression  ‚îÇ 0.78     ‚îÇ 0.74 ‚îÇ 0.00        ‚îÇ 0.81       ‚îÇ 0.54      ‚îÇ 0.65   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Passive Aggressive   ‚îÇ 0.77     ‚îÇ 0.69 ‚îÇ 0.02        ‚îÇ 0.90       ‚îÇ 0.45      ‚îÇ 0.60   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ RidgeClassifier      ‚îÇ 0.77     ‚îÇ 0.72 ‚îÇ 0.00        ‚îÇ 0.86       ‚îÇ 0.47      ‚îÇ 0.61   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ AdaBoost             ‚îÇ 0.76     ‚îÇ 0.68 ‚îÇ 0.01        ‚îÇ 0.99       ‚îÇ 0.38      ‚îÇ 0.54   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ SGDC                 ‚îÇ 0.75     ‚îÇ 0.66 ‚îÇ 0.00        ‚îÇ 0.99       ‚îÇ 0.34      ‚îÇ 0.50   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ KNN                  ‚îÇ 0.74     ‚îÇ 0.72 ‚îÇ 0.00        ‚îÇ 0.65       ‚îÇ 0.66      ‚îÇ 0.66   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">DummyClassifier</span>      ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.62</span>     ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.39</span> ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>        ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>       ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>      ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>   ‚îÇ          ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                        Base model training Comparison (100% Sampled dataset)                        \u001b[0m\n",
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mAlgorithm           \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mR2 score\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mMAE \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mK-Fold mean\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mK-Fold std\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mPresicion\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mRecall\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mf1-score\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ \u001b[1;32mStacking\u001b[0m             ‚îÇ \u001b[1;32m0.87\u001b[0m     ‚îÇ \u001b[1;32m0.85\u001b[0m ‚îÇ \u001b[1;32m0.00\u001b[0m        ‚îÇ \u001b[1;32m0.86\u001b[0m       ‚îÇ \u001b[1;32m0.79\u001b[0m      ‚îÇ \u001b[1;32m0.82\u001b[0m   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Bagging              ‚îÇ 0.87     ‚îÇ 0.86 ‚îÇ 0.00        ‚îÇ 0.85       ‚îÇ 0.79      ‚îÇ 0.82   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ LGBMClassifier       ‚îÇ 0.87     ‚îÇ 0.86 ‚îÇ 0.00        ‚îÇ 0.86       ‚îÇ 0.78      ‚îÇ 0.82   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Hard Voting          ‚îÇ 0.87     ‚îÇ 0.85 ‚îÇ 0.00        ‚îÇ 0.88       ‚îÇ 0.75      ‚îÇ 0.81   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ CatBoost             ‚îÇ 0.87     ‚îÇ 0.85 ‚îÇ 0.00        ‚îÇ 0.86       ‚îÇ 0.78      ‚îÇ 0.82   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ XGBoost              ‚îÇ 0.87     ‚îÇ 0.85 ‚îÇ 0.00        ‚îÇ 0.86       ‚îÇ 0.77      ‚îÇ 0.81   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ HistGradientBoosting ‚îÇ 0.86     ‚îÇ 0.85 ‚îÇ 0.00        ‚îÇ 0.85       ‚îÇ 0.77      ‚îÇ 0.81   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Soft Voting          ‚îÇ 0.86     ‚îÇ 0.84 ‚îÇ 0.00        ‚îÇ 0.89       ‚îÇ 0.73      ‚îÇ 0.80   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ RandomForest         ‚îÇ 0.86     ‚îÇ 0.84 ‚îÇ 0.00        ‚îÇ 0.88       ‚îÇ 0.73      ‚îÇ 0.80   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ GradientBoosting     ‚îÇ 0.84     ‚îÇ 0.83 ‚îÇ 0.00        ‚îÇ 0.84       ‚îÇ 0.72      ‚îÇ 0.78   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Bagged DT            ‚îÇ 0.84     ‚îÇ 0.82 ‚îÇ 0.00        ‚îÇ 0.82       ‚îÇ 0.74      ‚îÇ 0.78   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ MLPC                 ‚îÇ 0.84     ‚îÇ 0.82 ‚îÇ 0.00        ‚îÇ 0.82       ‚îÇ 0.73      ‚îÇ 0.77   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ DecisionTree         ‚îÇ 0.84     ‚îÇ 0.82 ‚îÇ 0.00        ‚îÇ 0.79       ‚îÇ 0.77      ‚îÇ 0.78   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ SVC                  ‚îÇ 0.82     ‚îÇ 0.80 ‚îÇ 0.00        ‚îÇ 0.83       ‚îÇ 0.66      ‚îÇ 0.74   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ ExtraTrees           ‚îÇ 0.82     ‚îÇ 0.78 ‚îÇ 0.00        ‚îÇ 0.93       ‚îÇ 0.56      ‚îÇ 0.70   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Logistic Regression  ‚îÇ 0.78     ‚îÇ 0.74 ‚îÇ 0.00        ‚îÇ 0.81       ‚îÇ 0.54      ‚îÇ 0.65   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Passive Aggressive   ‚îÇ 0.77     ‚îÇ 0.69 ‚îÇ 0.02        ‚îÇ 0.90       ‚îÇ 0.45      ‚îÇ 0.60   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ RidgeClassifier      ‚îÇ 0.77     ‚îÇ 0.72 ‚îÇ 0.00        ‚îÇ 0.86       ‚îÇ 0.47      ‚îÇ 0.61   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ AdaBoost             ‚îÇ 0.76     ‚îÇ 0.68 ‚îÇ 0.01        ‚îÇ 0.99       ‚îÇ 0.38      ‚îÇ 0.54   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ SGDC                 ‚îÇ 0.75     ‚îÇ 0.66 ‚îÇ 0.00        ‚îÇ 0.99       ‚îÇ 0.34      ‚îÇ 0.50   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ KNN                  ‚îÇ 0.74     ‚îÇ 0.72 ‚îÇ 0.00        ‚îÇ 0.65       ‚îÇ 0.66      ‚îÇ 0.66   ‚îÇ          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ \u001b[1;31mDummyClassifier\u001b[0m      ‚îÇ \u001b[1;31m0.62\u001b[0m     ‚îÇ \u001b[1;31m0.39\u001b[0m ‚îÇ \u001b[1;31m0.00\u001b[0m        ‚îÇ \u001b[1;31m0.00\u001b[0m       ‚îÇ \u001b[1;31m0.00\u001b[0m      ‚îÇ \u001b[1;31m0.00\u001b[0m   ‚îÇ          ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "temp_console = Console(record=True)\n",
    "temp_console.print(table)\n",
    "text = temp_console.export_text()\n",
    "with open('results/baseline_model.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbf6298",
   "metadata": {},
   "source": [
    "# Next step - Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272905b9",
   "metadata": {},
   "source": [
    "<a href=\"FS/without_fs.ipynb\" target=\"_blank\" style=\"text-decoration: none;\">\n",
    "    <button style=\"\n",
    "        background-color: #45a049;\n",
    "        color: white; \n",
    "        padding: 12px 24px; \n",
    "        font-size: 16px; \n",
    "        border: none; \n",
    "        border-radius: 8px;\n",
    "        cursor: pointer;\n",
    "        transition: background-color 0.3s;\n",
    "    \" onmouseover=\"this.style.backgroundColor='#45a049'\" onmouseout=\"this.style.backgroundColor='#4CAF50'\">\n",
    "        Without Feature selection \n",
    "    </button>\n",
    "</a>\n",
    "\n",
    "<a href=\"FS/filter.ipynb\" target=\"_blank\" style=\"text-decoration: none;\">\n",
    "    <button style=\"\n",
    "        background-color: #45a049;\n",
    "        color: white; \n",
    "        padding: 12px 24px; \n",
    "        font-size: 16px; \n",
    "        border: none; \n",
    "        border-radius: 8px;\n",
    "        cursor: pointer;\n",
    "        transition: background-color 0.3s;\n",
    "    \" onmouseover=\"this.style.backgroundColor='#45a049'\" onmouseout=\"this.style.backgroundColor='#4CAF50'\">\n",
    "        Filter method\n",
    "    </button>\n",
    "</a>\n",
    "\n",
    "<a href=\"FS/embedded.ipynb\" target=\"_blank\" style=\"text-decoration: none;\">\n",
    "    <button style=\"\n",
    "        background-color: #45a049;\n",
    "        color: white; \n",
    "        padding: 12px 24px; \n",
    "        font-size: 16px; \n",
    "        border: none; \n",
    "        border-radius: 8px;\n",
    "        cursor: pointer;\n",
    "        transition: background-color 0.3s;\n",
    "    \" onmouseover=\"this.style.backgroundColor='#45a049'\" onmouseout=\"this.style.backgroundColor='#4CAF50'\">\n",
    "        Embedded method\n",
    "    </button>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0fc7c5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
